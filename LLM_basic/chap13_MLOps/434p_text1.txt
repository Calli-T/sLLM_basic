{   MLOps
    {   MLOps란
        데브옵스: 소프트웨어 개발 운영의 협업과 자동화
        MLOps: 위에 데이터와 머신러닝을 얹은거

        모든 과정을 자동화하고 효율화 한다
    }

    {   MLOps의 순서는
        데이터 준비 -> 모델 학습 -> 모델 저장소 <-> 모델 평가 -> 모델 배포 -> 모니터링 -> (재학습 사이클) -> 데이터 준비
        {   용어, 이런게 있구나 알아만 두자
            머신러닝 파이프라인은 데이터준비 ~ 모델 저장소(평가) 까지를 좁게 간주하거나, 넓게는 위 프로세스 모두를 포함함
            CI(Continuous Integration)은 일반적으로 배포 직전까지의 단계를, CD(Continuous Deployment)는 배포를 나타내는 개념,
            CT는 아무래도 Continuous Pipeline을 의미하는듯
        }
        어쨌거나 준비/학습/평가/배포/모니터링을 자동 반복하는 개념인듯
    }

    재현성이란걸 보장해야하는데
    재현성: 같은 ML 워크 플로를 반복했을 때 동일한 모델을 얻을 수 있는지의 여부
    모든 단계가 문서화되고 버전관리가 이루어져야 이전 모델을 동일하게 재현할 수 있다
    데이터와 모델, 코드 전체에 버전 관리가 이뤄지고
    모든 단계의 입력값과 파라미터를 추적하고 기록해야한다.
    학습을 자동으로 트리거하고, 새로운 데이터로 지속적으로 모델을 업데이트 하는듯
    모델 성능 저하시 자동으로 재학습과 배포가 이뤄짐으써 모델이 항상 최적의 상태를 유지하도록 만듬
    이건 데브옵스의 지속적 통합/배포 개념을 머신러닝에 적용한 것

    데이터 관리 / 실험 관리 / 모델 저장소 / 모델 모니터링이란 주제를 다룬다고 한다

    {   데이터 관리
        {   뭘 하는건데?
            원천데이터를
            1. 데이터 범위 결정,
            2. 오류 제거 등 전처리
            3. 특성공학적 가공
            위 셋에 따라최종적인 데이터셋의 형태가 달라진다
            +
            그리고 만든 데이터셋을 버전을 붙여 관리하고
            어떤 데이터셋으로 모델을 학습했는지 기록하는것이 필요
            여기 쓰이는 도구는 DVC라고 한다
        }

        포함 시킬 데이터의 범위, 전처리, 특성공학※에 따라 어떤 특성을 추가할지에 따라 학습 데이터셋이 달라진다.
        ※ 특성공학은 원시 데이터를 모델이 더 잘 이해하도록 유용한 특성을 생성하는 작업, 스케일링이나 정규화, 원핫 - 인코딩 등등 필요한 정보를 데이터에서 뽑아내는 것
        ex) 추천 모델을 만들 때 고객의 구매 데이터만 볼 것인지, 장바구니나 조회한 데이터까지 학습 데이터에 추가할 것인지 결정
    }

    {   실험 관리
        뭘 하는가?: 학습에는 모델 + 하이퍼파라미터의 선택이 필요하며, MLOps에서는 이를 기록해둘 필요가 있다.
        도구는 뭐가 있나?: MLflow, W&B가 있음

        ※ 협업할 때 특히나 유용하다.
    }

    {   모델 저장소
        {  뭘하고, 무슨 특징이 있나?
            위 실험에서 여러 버전의 모델이 생성되는데,
            이 모든 모델을 체계적으로 통합하여 체계적으로 관리하는 것이다.

            모델의 전체 수명 주기를 추척하고, 변경 이력을 기억하므로,
            문제가 생기는 경우 빠르게 롤백 할 수 있다.
            또한 모델의 메타 데이터(생성일, 성능 지표, 하이퍼파라미터) 등을 저장하여 빠른 정보확인이 가능하다.

            여기 연동하면 배포와 관리가 빨라지고 협업을 촉진한다.
        }
       도구는 뭐가 있나?: MLflow 모델 저장소, AWS 세이지 메이커 모델 저장소 등등이 있다.
    }

    {   모델 모니터링
        {   왜 하는가?
            1. 정상적인 요청에 정상적인 반환을 하는지 알아봐야함
            2. 시간에 따른 입력 데이터 변동으로 모델의 성능 저하가 발생할 수 있다.

            이 두 문제를 빠르게 감지하고 대응하기 위함

            추가로
            3. 시스템의 기본적인 지표를 기록하여 시스템에 이상이 없는지, 리소스가 추가로 필요하지는 않은지, 낭비는 없는지를 체크한다.

            {   필요한 경우의 예시
            리뷰의 긍정 / 부정을 분류하는 모델을 개발했는데
            배포 이후 서비스를 방문하는 사람의 직무, 연령, 성별 분포에 변화가 생기면
            사용하는 표현, 리뷰의 길이 등 모델을 학습 시켰을 때와 달라 질 수 있다.
            머신러닝은 기본적으로 일반화(= 새로 보는 데이터도 잘 처리함) 성능이 높도록 학습하나,
            기본적으로 학습한 데이터와 유사한 데이터 분포에서 가장 좋은 성능을 보인다.
            이런 경우 새로운 데이터로 재학습을 하는 것이 좋음
            }
        }

        무슨 도구를 쓰는가?: 프로메테우스, 그라파나는 오픈소스, AWS 세이지메이커의 모델모니터 같은 관리형 서비스도 있다.
    }
}

