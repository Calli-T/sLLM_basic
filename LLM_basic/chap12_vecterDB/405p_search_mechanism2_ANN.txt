{   ANN이란
    {   서문
        ANN은 KNN과 달리 약간의 정확도를 희생해서 훨씬 더 빠른 검색  속도를 제공한다
        KNN이 느린 이유는 저장된 모든 벡터를 비교하면서 거리를 계산하기 때문인데,
        이를 극복하기위해 임베딩 벡터를 빠르게 탐색할 수 있는 구조로 저장하여 검색의 범위를 좁힌다
        Inverted File Index와 Hierarchical Navigable Samll World가 있다

        IVF는 데이터셋 벡터를 클러스터로 그룹화하는 근사 KNN 검색,
        인덱싱 시점에 데이터를 가져와 중심점 클러스터를 형성함
        쿼리할 때는 가까운 중심점을 찾은 다음, 해당 중심점 내부에서만 검색함
        검색되지 않은 클러스터의 이웃을 놓칠 수 있으나, 검색 시간을 크게 줄일 수 있음

        HNSW
    }

    {   ANN에서 성능 지표
        성능
        재현율 = (예측 중 정답에 해당하는 수) / (실제 정답의 수) ※ 정밀도는 찾아낸 것 중 실제 정답의 비율, F1은 이 둘의 조화평균

        ANN에서의 재현율의 의미는 다음과 같다
        (ANN 검색의 재현율) = (KNN으로 찾은 실제 가장 가까운 K개 중 ANN이 찾은 개수) / K
    }

    {   HNSW
        요약: 여러 계층을 두어 검색한다. 상위 계층으로 갈 수록 듬성듬성 배치하고, 상위 계층의 데이터는 하위 계층에 모두 존재하도록 계층 구조를 짠다.
        검색할 때는 상위 계층에서 대략적인 위치를 찾고, 하위 계층에서 상위 계층에서 찾은 위치 근처의 이웃을 탐색하며 갱신하여, 최하위 계층에서 정확한 위치를 검색한다.

        HNSW는 그래프 기반 인덱싱 구조이다.
        상위 계층에서는 연결이 적고 하위 계층에는 연결이 밀집된 다층 그래프를 구축한다
        최상위 계층에는 연결이 적어 데이터 사이의 거리가 멀다(한 번에 탐색할 때 이동하는 거리가 길다)
        하위 계층에서는 여러 연결이 있다.
        검색은 최상위 계층에서 시작해서 아래 계층으로 진행한다

        {   NSW, 탐색 가능한 작은 세계
            {   기초 개념 1: 작은 세계
                일단 NSW도 그래프이므로, 당연히 노드와 엣지로 이루어지는데
                노드는 데이터를, 엣지는 노드끼리의 (탐색용) 선을 의미함

                모든 노드에서 모든 모드로의 간선이 존재하는 그래프이며, 정확하지만 검색 오버헤드가 크다
                반대로, 완전히 무작위로 연결된 그래프는 노드에 연결 상태에 따라 복불복이 너무나 크다
                따라서, NSW 규칙을 가진 간선 패턴에 무작위 엣지를 추가하는 형태로 만들어진다
            }

            {   기초 개념 2: 계층 구조
                위 작은 세계 방식은, 현재 노드보다 더 가까운 이웃이 없으면 탐색이 멈추기 때문에 검색이 지역 최솟값에서 머물러 버리는 경우가 존재한다
                이를 해결하기 위한 것이 계층 구조이다

                그리고 그 구조는 스킵리스트를 응용한 것이다
                {   스킵 리스트
                    여러 리스트를 계층적으로 둔 연결리스트로,
                    높은 레벨에서는 노드를 듬성 듬성 두었고, 낮은 레벨은 노드가 모두 차있다
                    높은 레벨에서 대략적인 위치를 파악하고
                    아래의 레벨로 가면서 (높은 레벨에서 찾은 위치 근처에서 시작하여) 세세하게 찾으며,
                    (해당 행동을 반복해가며) 정확한 위치는 최하위 레벨에서 찾는다. 따라서, 지역 최소값이 나와도 탐색을 멈추지 않으므로 거기에 빠지지 않는다
                }

                {   그럼 각 계층에 들어갈 노드(= 데이터)는 어떻게 정하는가?
                    무작위 값을 뽑아 상위, 중위, 하위에 존재할 데이터를 뽑는 방식(※ 단, 상위 계층에 있는 데이터는 하위의 계층에 그대로 존재한다)
                }
            }
        }

        {   핵심 파라미터
            ※ 다음 url을 참고
            https://aws.amazon.com/ko/blogs/tech/choose-the-k-nn-algorithm-for-your-billion-scale-use-case-with-opensearch/

            m: 하나의 벡터에 연결 하는 다른 벡터의 최소 개수,
            노드간 연결을 구성할 때 각 노드는 적어도 m개의 다른 노드와 연결되며, 그래프의 연결성이 유지된다
            값이 클 수록 색인 시간이 늘고 메모리 사용량이 늘지만, 연결이 조밀해지므로 검색 정확도가 높아진다

            ef_construction: 색인 과정에서 가장 가까운 M개를 선택하기 위해 저장하는 후보의 수
            이 값이 더 클 수록 더 좋은 이웃을 찾을 확률이 좋아지며, 정밀한 그래프가 생성되는 대신 색인 시간과 메모리 사용량은 증가
            노드가 그래프에 삽입될 때, 새 노드를 쿼리 벡터로 삼아 그래프를 쿼리하여 해당 노드의 m개 에지를 찾음, 이 탐색을 위한 후보 대기열 크기를 제어

            ef_search: 검색 과정에서 가장 가까운 K개를 선택할 때 저장하는 후보의 수
            값이 클 수록 더 많은 노드를 탐색하며, 정확도는 올라가고 검색 시간도 늘어남
        }

        동작 방식 요약 ※ 채찍피티, 부조종수, 쌍둥이 모두가 HNSW의 기본 원리랑 일치한다고함
        1. 새 데이터를 색인화 할 때는 ef_construction 만큼의 이웃을 검색 때와 같은 방식으로 탐색하여 가장 가까운 노드 m개에 대한 간선을 유지한다.
        2. 각 층에서 ef_construction을 유지하는 과정에서, 자연스럽게 NSW를 유지한다
        3. 검색할 때는 한 층에서 ef_search개만큼의 후보군을 최상위에서 찾고,
        4. 다음 레벨에서 후보군 + 후보군의 이웃 가운데 유사도가 높은 값을 ef_search만큼 추려내고 (우선 순위 큐 사용)
        5. 이를 마지막 층까지 반복하여 ef_search... 혹은 반환할 개수만큼 반환함
    }
}

실습 결과
M: 8 - 색인 시간: 22.87523579597473 s, 메모리 사용량: 581.23828125 MB
0.009 ms per query, R@1 0.612
M: 16 - 색인 시간: 28.39431858062744 s, 메모리 사용량: 629.94921875 MB
0.014 ms per query, R@1 0.700
M: 32 - 색인 시간: 56.85257625579834 s, 메모리 사용량: 736.7421875 MB
0.032 ms per query, R@1 0.860
M: 64 - 색인 시간: 78.74779915809631 s, 메모리 사용량: 1011.8828125 MB
0.055 ms per query, R@1 0.915
efConstruction: 40 - 색인 시간: 58.90766382217407 s, 메모리 사용량: 801.3359375 MB
0.028 ms per query, R@1 0.864
efConstruction: 80 - 색인 시간: 68.74590039253235 s, 메모리 사용량: 801.3359375 MB
0.023 ms per query, R@1 0.825
efConstruction: 160 - 색인 시간: 143.66875743865967 s, 메모리 사용량: 801.6640625 MB
0.032 ms per query, R@1 0.861
efConstruction: 320 - 색인 시간: 276.28720927238464 s, 메모리 사용량: 801.5859375 MB
0.044 ms per query, R@1 0.873
0.034 ms per query, R@1 0.873
0.051 ms per query, R@1 0.958
0.090 ms per query, R@1 0.985
0.158 ms per query, R@1 0.993