184p
분산학습은 GPU를 여러 개 활용해 딥러닝 모델을 학습시키는 것을 말한다.
갈래는 크게 두 가지
1. 모델의 학습 속도를 높이는것(작은 모델의 경우)
2. 1개 GPU로 학습이 어려울 정도로 모델이 큰 경우

모델이 작아 하나의 GPU에서 돌릴 수 있는 경우에는 여러 GPU에서 각각 모델을 올리고 병렬처리
이를 데이터 병렬화(Data parallelism)이라 한다
-> 학습 속도가 늘어남

185p
하나의 GPU에 올리기 어려운 모델의 경우 모델 병렬화(Model parallelism)을 사용
이는 다시 층 별로 나눠 GPU로 올리는 파이프라인 병렬화와
한 층의 모델도 나눠서 GPU에 올리는 텐서 병렬화가 있다
-> 한 GPU에 다 못올리는 큰 모델을 학습가능함

※!
186p
파이프라인 병렬화의 경우 모델의 층 순서에 맞춰 순차적으로 연산함으로, 문제 없음
텐서 병렬화의 경우는? 하나의 층을 나눠 서로 다른 gpu에 올리기 때문에,
병렬화 전과 후에 동일한 결과를 구할지에 대한 해결책이 필요함
가중치를 한 열씩(열 방향으로) 분리한 경우는 입력을 복사해서 가중치 각각과 곱한걸 concat하고,
가중치를 행방향으로 분리한 경우는 곱한 행렬을 더하는 것으로 원본과 같은 연산이 가능함
요약: 텐서 병렬화 상황에서 원본과 같은 연산을 하기 위해서는 가중치를 분리한 방식에 따라 다른 처리를 해줘야한다.

187p
실제 사용법 그림
이것만 봐서는 잘 모르겠는데
중요한건 멀티헤드 어텐션 연산에서, 헤드를 각기 다른 GPU로 분리가 가능하다는 점이다
선형층이 헤드개수x3개만큼있는데, 입력X는 당연히 헤드 수 만큼 복제해야함

188p
데이터 병렬화는 동일한 모델을 여러 GPU에 중복으로 올리므로 메모리 낭비 발생,
이를 줄이는 방법이 존재함

ZeRO(Zero Redundancy Optimizer, 무?영 중복 최적화기): 모델 병렬화처럼 모델을 나눠 여러 GPU에 올리고,
각 GPU에서는 자신의 모델 부분의 연산만 수행하고, 그 상태를 저장하는 방법

메모리를 효율적을 사용하면서 속도도 유지할 수 있다.(는 것이 ZeRO)의 컨셉이다
모델 파라미터, 그레이디언트, 옵티마이저 상태를 GPU마다 부분적으로 나눠 가지고,
필요한 순간에만 모델 파라미터를 복사해 연산을 수행함

실전 꿀팁: 허깅페이스서 지원함
Accelerate의 딥스피드 사용 가이드에서 더 확인할 수 있다고 함