{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"collapsed":true,"id":"1d00oCMhWkHs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743249671829,"user_tz":-540,"elapsed":36829,"user":{"displayName":"재환김","userId":"10617165991486556387"}},"outputId":"4cc6bc74-c707-46f9-f5cd-ae9c71858355"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.2.1)\n","Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.0)\n","Requirement already satisfied: autotrain-advanced in /usr/local/lib/python3.11/dist-packages (0.8.36)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n","Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (4.12.2)\n","Requirement already satisfied: albumentations==1.4.23 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (1.4.23)\n","Requirement already satisfied: datasets~=3.2.0 in /usr/local/lib/python3.11/dist-packages (from datasets[vision]~=3.2.0->autotrain-advanced) (3.2.0)\n","Requirement already satisfied: evaluate==0.4.3 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (0.4.3)\n","Requirement already satisfied: ipadic==1.0.0 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (1.0.0)\n","Requirement already satisfied: jiwer==3.0.5 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (3.0.5)\n","Requirement already satisfied: joblib==1.4.2 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (1.4.2)\n","Requirement already satisfied: loguru==0.7.3 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (0.7.3)\n","Requirement already satisfied: pandas==2.2.3 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (2.2.3)\n","Requirement already satisfied: nltk==3.9.1 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (3.9.1)\n","Requirement already satisfied: optuna==4.1.0 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (4.1.0)\n","Requirement already satisfied: Pillow==11.0.0 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (11.0.0)\n","Requirement already satisfied: sacremoses==0.1.1 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (0.1.1)\n","Requirement already satisfied: scikit-learn==1.6.0 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (1.6.0)\n","Requirement already satisfied: sentencepiece==0.2.0 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (0.2.0)\n","Requirement already satisfied: werkzeug==3.1.3 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (3.1.3)\n","Requirement already satisfied: xgboost==2.1.3 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (2.1.3)\n","Requirement already satisfied: einops==0.8.0 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (0.8.0)\n","Requirement already satisfied: cryptography==44.0.0 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (44.0.0)\n","Requirement already satisfied: nvitop==1.3.2 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (1.3.2)\n","Requirement already satisfied: tensorboard==2.18.0 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (2.18.0)\n","Requirement already satisfied: peft==0.14.0 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (0.14.0)\n","Requirement already satisfied: trl==0.13.0 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (0.13.0)\n","Requirement already satisfied: tiktoken==0.8.0 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (0.8.0)\n","Requirement already satisfied: rouge-score==0.1.2 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (0.1.2)\n","Requirement already satisfied: py7zr==0.22.0 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (0.22.0)\n","Requirement already satisfied: fastapi==0.115.6 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (0.115.6)\n","Requirement already satisfied: uvicorn==0.34.0 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (0.34.0)\n","Requirement already satisfied: python-multipart==0.0.20 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (0.0.20)\n","Requirement already satisfied: pydantic==2.10.4 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (2.10.4)\n","Requirement already satisfied: hf-transfer in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (0.1.9)\n","Requirement already satisfied: pyngrok==7.2.1 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (7.2.1)\n","Requirement already satisfied: authlib==1.4.0 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (1.4.0)\n","Requirement already satisfied: itsdangerous==2.2.0 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (2.2.0)\n","Requirement already satisfied: seqeval==1.2.2 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (1.2.2)\n","Requirement already satisfied: httpx==0.28.1 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (0.28.1)\n","Requirement already satisfied: timm==1.0.12 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (1.0.12)\n","Requirement already satisfied: torchmetrics==1.6.0 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (1.6.0)\n","Requirement already satisfied: pycocotools==2.0.8 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (2.0.8)\n","Requirement already satisfied: sentence-transformers==3.3.1 in /usr/local/lib/python3.11/dist-packages (from autotrain-advanced) (3.3.1)\n","Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.23->autotrain-advanced) (1.14.1)\n","Requirement already satisfied: albucore==0.0.21 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.23->autotrain-advanced) (0.0.21)\n","Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.23->autotrain-advanced) (0.2.2)\n","Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.23->autotrain-advanced) (4.11.0.86)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography==44.0.0->autotrain-advanced) (1.17.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate==0.4.3->autotrain-advanced) (0.3.8)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate==0.4.3->autotrain-advanced) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate==0.4.3->autotrain-advanced) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate==0.4.3->autotrain-advanced) (2024.9.0)\n","Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi==0.115.6->autotrain-advanced) (0.41.3)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx==0.28.1->autotrain-advanced) (4.9.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.28.1->autotrain-advanced) (2025.1.31)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.28.1->autotrain-advanced) (1.0.7)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx==0.28.1->autotrain-advanced) (3.10)\n","Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from jiwer==3.0.5->autotrain-advanced) (8.1.8)\n","Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.11/dist-packages (from jiwer==3.0.5->autotrain-advanced) (3.12.2)\n","Requirement already satisfied: nvidia-ml-py<12.536.0a0,>=11.450.51 in /usr/local/lib/python3.11/dist-packages (from nvitop==1.3.2->autotrain-advanced) (12.535.161)\n","Requirement already satisfied: cachetools>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from nvitop==1.3.2->autotrain-advanced) (5.5.2)\n","Requirement already satisfied: termcolor>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from nvitop==1.3.2->autotrain-advanced) (2.5.0)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna==4.1.0->autotrain-advanced) (1.15.2)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna==4.1.0->autotrain-advanced) (6.9.0)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna==4.1.0->autotrain-advanced) (2.0.39)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.3->autotrain-advanced) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.3->autotrain-advanced) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.3->autotrain-advanced) (2025.1)\n","Requirement already satisfied: texttable in /usr/local/lib/python3.11/dist-packages (from py7zr==0.22.0->autotrain-advanced) (1.7.0)\n","Requirement already satisfied: pycryptodomex>=3.16.0 in /usr/local/lib/python3.11/dist-packages (from py7zr==0.22.0->autotrain-advanced) (3.22.0)\n","Requirement already satisfied: pyzstd>=0.15.9 in /usr/local/lib/python3.11/dist-packages (from py7zr==0.22.0->autotrain-advanced) (0.16.2)\n","Requirement already satisfied: pyppmd<1.2.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from py7zr==0.22.0->autotrain-advanced) (1.1.1)\n","Requirement already satisfied: pybcj<1.1.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from py7zr==0.22.0->autotrain-advanced) (1.0.3)\n","Requirement already satisfied: multivolumefile>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from py7zr==0.22.0->autotrain-advanced) (0.2.3)\n","Requirement already satisfied: inflate64<1.1.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from py7zr==0.22.0->autotrain-advanced) (1.0.1)\n","Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from py7zr==0.22.0->autotrain-advanced) (1.1.0)\n","Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools==2.0.8->autotrain-advanced) (3.10.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.10.4->autotrain-advanced) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.10.4->autotrain-advanced) (2.27.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score==0.1.2->autotrain-advanced) (1.4.0)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score==0.1.2->autotrain-advanced) (1.17.0)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.0->autotrain-advanced) (3.6.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.18.0->autotrain-advanced) (1.71.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.18.0->autotrain-advanced) (3.7)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.18.0->autotrain-advanced) (5.29.4)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.18.0->autotrain-advanced) (75.1.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.18.0->autotrain-advanced) (0.7.2)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm==1.0.12->autotrain-advanced) (0.21.0+cu124)\n","Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.6.0->autotrain-advanced) (0.14.2)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl==0.13.0->autotrain-advanced) (13.9.4)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn==0.34.0->autotrain-advanced) (0.14.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug==3.1.3->autotrain-advanced) (3.0.2)\n","Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost==2.1.3->autotrain-advanced) (2.21.5)\n","Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.21->albumentations==1.4.23->autotrain-advanced) (3.12.3)\n","Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.21->albumentations==1.4.23->autotrain-advanced) (6.2.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets~=3.2.0->datasets[vision]~=3.2.0->autotrain-advanced) (18.1.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets~=3.2.0->datasets[vision]~=3.2.0->autotrain-advanced) (3.11.14)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (0.6.2)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.4.127)\n","Collecting triton==3.2.0 (from torch>=1.10.0->accelerate)\n","  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna==4.1.0->autotrain-advanced) (1.1.3)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography==44.0.0->autotrain-advanced) (2.22)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets~=3.2.0->datasets[vision]~=3.2.0->autotrain-advanced) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets~=3.2.0->datasets[vision]~=3.2.0->autotrain-advanced) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets~=3.2.0->datasets[vision]~=3.2.0->autotrain-advanced) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets~=3.2.0->datasets[vision]~=3.2.0->autotrain-advanced) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets~=3.2.0->datasets[vision]~=3.2.0->autotrain-advanced) (6.2.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets~=3.2.0->datasets[vision]~=3.2.0->autotrain-advanced) (0.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets~=3.2.0->datasets[vision]~=3.2.0->autotrain-advanced) (1.18.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.8->autotrain-advanced) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.8->autotrain-advanced) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.8->autotrain-advanced) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.8->autotrain-advanced) (1.4.8)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.8->autotrain-advanced) (3.2.1)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna==4.1.0->autotrain-advanced) (3.1.1)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx==0.28.1->autotrain-advanced) (1.3.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl==0.13.0->autotrain-advanced) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl==0.13.0->autotrain-advanced) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl==0.13.0->autotrain-advanced) (0.1.2)\n","Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: triton\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.1.0\n","    Uninstalling triton-2.1.0:\n","      Successfully uninstalled triton-2.1.0\n","Successfully installed triton-3.2.0\n","Collecting triton==2.1.0\n","  Using cached triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton==2.1.0) (3.18.0)\n","Using cached triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n","Installing collected packages: triton\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.2.0\n","    Uninstalling triton-3.2.0:\n","      Successfully uninstalled triton-3.2.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.6.0+cu124 requires triton==3.2.0; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have triton 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed triton-2.1.0\n"]}],"source":["!pip install transformers accelerate bitsandbytes autotrain-advanced\n","!pip install -U triton==2.1.0"]},{"cell_type":"code","source":["!pip list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"byBvBzHemz8f","executionInfo":{"status":"ok","timestamp":1743080203932,"user_tz":-540,"elapsed":1540,"user":{"displayName":"김재환","userId":"12736849163701558078"}},"outputId":"963630a9-d153-4233-da8e-d4bdf6ed4b87","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Package                            Version\n","---------------------------------- -------------------\n","absl-py                            1.4.0\n","accelerate                         1.2.1\n","aiohappyeyeballs                   2.6.1\n","aiohttp                            3.11.14\n","aiosignal                          1.3.2\n","alabaster                          1.0.0\n","albucore                           0.0.21\n","albumentations                     1.4.23\n","ale-py                             0.10.2\n","alembic                            1.15.1\n","altair                             5.5.0\n","annotated-types                    0.7.0\n","anyio                              4.9.0\n","argon2-cffi                        23.1.0\n","argon2-cffi-bindings               21.2.0\n","array_record                       0.7.1\n","arviz                              0.21.0\n","astropy                            7.0.1\n","astropy-iers-data                  0.2025.3.17.0.34.53\n","astunparse                         1.6.3\n","atpublic                           5.1\n","attrs                              25.3.0\n","audioread                          3.0.1\n","Authlib                            1.4.0\n","autograd                           1.7.0\n","autotrain-advanced                 0.8.36\n","babel                              2.17.0\n","backcall                           0.2.0\n","beautifulsoup4                     4.13.3\n","betterproto                        2.0.0b6\n","bigframes                          1.41.0\n","bigquery-magics                    0.8.0\n","bitsandbytes                       0.45.0\n","bleach                             6.2.0\n","blinker                            1.9.0\n","blis                               1.2.0\n","blosc2                             3.2.0\n","bokeh                              3.6.3\n","Bottleneck                         1.4.2\n","bqplot                             0.12.44\n","branca                             0.8.1\n","Brotli                             1.1.0\n","CacheControl                       0.14.2\n","cachetools                         5.5.2\n","catalogue                          2.0.10\n","certifi                            2025.1.31\n","cffi                               1.17.1\n","chardet                            5.2.0\n","charset-normalizer                 3.4.1\n","chex                               0.1.89\n","clarabel                           0.10.0\n","click                              8.1.8\n","cloudpathlib                       0.21.0\n","cloudpickle                        3.1.1\n","cmake                              3.31.6\n","cmdstanpy                          1.2.5\n","colorcet                           3.1.0\n","colorlog                           6.9.0\n","colorlover                         0.3.0\n","colour                             0.1.5\n","community                          1.0.0b1\n","confection                         0.1.5\n","cons                               0.4.6\n","contourpy                          1.3.1\n","cramjam                            2.9.1\n","cryptography                       44.0.0\n","cuda-python                        12.6.2.post1\n","cudf-cu12                          25.2.1\n","cudf-polars-cu12                   25.2.2\n","cufflinks                          0.17.3\n","cuml-cu12                          25.2.1\n","cupy-cuda12x                       13.3.0\n","cuvs-cu12                          25.2.1\n","cvxopt                             1.3.2\n","cvxpy                              1.6.4\n","cycler                             0.12.1\n","cyipopt                            1.5.0\n","cymem                              2.0.11\n","Cython                             3.0.12\n","dask                               2024.12.1\n","dask-cuda                          25.2.0\n","dask-cudf-cu12                     25.2.2\n","dask-expr                          1.1.21\n","datascience                        0.17.6\n","datasets                           3.2.0\n","db-dtypes                          1.4.2\n","dbus-python                        1.2.18\n","debugpy                            1.8.0\n","decorator                          4.4.2\n","defusedxml                         0.7.1\n","Deprecated                         1.2.18\n","diffusers                          0.32.2\n","dill                               0.3.8\n","distributed                        2024.12.1\n","distributed-ucxx-cu12              0.42.0\n","distro                             1.9.0\n","dlib                               19.24.2\n","dm-tree                            0.1.9\n","docker-pycreds                     0.4.0\n","docstring_parser                   0.16\n","docutils                           0.21.2\n","dopamine_rl                        4.1.2\n","duckdb                             1.2.1\n","earthengine-api                    1.5.7\n","easydict                           1.13\n","editdistance                       0.8.1\n","eerepr                             0.1.1\n","einops                             0.8.0\n","en_core_web_sm                     3.8.0\n","entrypoints                        0.4\n","et_xmlfile                         2.0.0\n","etils                              1.12.2\n","etuples                            0.3.9\n","eval_type_backport                 0.2.2\n","evaluate                           0.4.3\n","Farama-Notifications               0.0.4\n","fastai                             2.7.19\n","fastapi                            0.115.6\n","fastcore                           1.7.29\n","fastdownload                       0.0.7\n","fastjsonschema                     2.21.1\n","fastprogress                       1.0.3\n","fastrlock                          0.8.3\n","filelock                           3.18.0\n","firebase-admin                     6.7.0\n","Flask                              3.1.0\n","flatbuffers                        25.2.10\n","flax                               0.10.4\n","folium                             0.19.5\n","fonttools                          4.56.0\n","frozendict                         2.4.6\n","frozenlist                         1.5.0\n","fsspec                             2024.9.0\n","future                             1.0.0\n","gast                               0.6.0\n","gcsfs                              2025.3.0\n","GDAL                               3.6.4\n","gdown                              5.2.0\n","geemap                             0.35.3\n","geocoder                           1.38.1\n","geographiclib                      2.0\n","geopandas                          1.0.1\n","geopy                              2.4.1\n","gin-config                         0.5.0\n","gitdb                              4.0.12\n","GitPython                          3.1.44\n","glob2                              0.7\n","google                             2.0.3\n","google-ai-generativelanguage       0.6.15\n","google-api-core                    2.24.2\n","google-api-python-client           2.164.0\n","google-auth                        2.38.0\n","google-auth-httplib2               0.2.0\n","google-auth-oauthlib               1.2.1\n","google-cloud-aiplatform            1.84.0\n","google-cloud-bigquery              3.29.0\n","google-cloud-bigquery-connection   1.18.2\n","google-cloud-bigquery-storage      2.29.1\n","google-cloud-bigtable              2.30.0\n","google-cloud-core                  2.4.3\n","google-cloud-dataproc              5.18.1\n","google-cloud-datastore             2.20.2\n","google-cloud-firestore             2.20.1\n","google-cloud-functions             1.20.2\n","google-cloud-iam                   2.18.3\n","google-cloud-language              2.17.1\n","google-cloud-pubsub                2.29.0\n","google-cloud-resource-manager      1.14.2\n","google-cloud-spanner               3.53.0\n","google-cloud-storage               2.19.0\n","google-cloud-translate             3.20.2\n","google-colab                       1.0.0\n","google-crc32c                      1.7.0\n","google-genai                       1.7.0\n","google-generativeai                0.8.4\n","google-pasta                       0.2.0\n","google-resumable-media             2.7.2\n","google-spark-connect               0.5.2\n","googleapis-common-protos           1.69.2\n","googledrivedownloader              1.1.0\n","graphviz                           0.20.3\n","greenlet                           3.1.1\n","grpc-google-iam-v1                 0.14.2\n","grpc-interceptor                   0.15.4\n","grpcio                             1.71.0\n","grpcio-status                      1.71.0\n","grpclib                            0.4.7\n","gspread                            6.2.0\n","gspread-dataframe                  4.0.0\n","gym                                0.25.2\n","gym-notices                        0.0.8\n","gymnasium                          1.1.1\n","h11                                0.14.0\n","h2                                 4.2.0\n","h5netcdf                           1.6.1\n","h5py                               3.13.0\n","hdbscan                            0.8.40\n","hf_transfer                        0.1.9\n","highspy                            1.9.0\n","holidays                           0.69\n","holoviews                          1.20.2\n","hpack                              4.1.0\n","html5lib                           1.1\n","httpcore                           1.0.7\n","httpimport                         1.4.1\n","httplib2                           0.22.0\n","httpx                              0.28.1\n","huggingface-hub                    0.27.0\n","humanize                           4.12.1\n","hyperframe                         6.1.0\n","hyperopt                           0.2.7\n","ibis-framework                     9.5.0\n","idna                               3.10\n","imageio                            2.37.0\n","imageio-ffmpeg                     0.6.0\n","imagesize                          1.4.1\n","imbalanced-learn                   0.13.0\n","immutabledict                      4.2.1\n","importlib_metadata                 8.6.1\n","importlib_resources                6.5.2\n","imutils                            0.5.4\n","inflate64                          1.0.1\n","inflect                            7.5.0\n","iniconfig                          2.1.0\n","intel-cmplr-lib-ur                 2025.1.0\n","intel-openmp                       2025.1.0\n","ipadic                             1.0.0\n","ipyevents                          2.0.2\n","ipyfilechooser                     0.6.0\n","ipykernel                          6.17.1\n","ipyleaflet                         0.19.2\n","ipyparallel                        8.8.0\n","ipython                            7.34.0\n","ipython-genutils                   0.2.0\n","ipython-sql                        0.5.0\n","ipytree                            0.2.2\n","ipywidgets                         7.7.1\n","itsdangerous                       2.2.0\n","jax                                0.5.2\n","jax-cuda12-pjrt                    0.5.1\n","jax-cuda12-plugin                  0.5.1\n","jaxlib                             0.5.1\n","jeepney                            0.7.1\n","jellyfish                          1.1.0\n","jieba                              0.42.1\n","Jinja2                             3.1.6\n","jiter                              0.9.0\n","jiwer                              3.0.5\n","joblib                             1.4.2\n","jsonpatch                          1.33\n","jsonpickle                         4.0.2\n","jsonpointer                        3.0.0\n","jsonschema                         4.23.0\n","jsonschema-specifications          2024.10.1\n","jupyter-client                     6.1.12\n","jupyter-console                    6.1.0\n","jupyter_core                       5.7.2\n","jupyter-leaflet                    0.19.2\n","jupyter-server                     1.16.0\n","jupyterlab_pygments                0.3.0\n","jupyterlab_widgets                 3.0.13\n","kaggle                             1.7.4.2\n","kagglehub                          0.3.10\n","keras                              3.8.0\n","keras-hub                          0.18.1\n","keras-nlp                          0.18.1\n","keyring                            23.5.0\n","kiwisolver                         1.4.8\n","langchain                          0.3.21\n","langchain-core                     0.3.47\n","langchain-text-splitters           0.3.7\n","langcodes                          3.5.0\n","langsmith                          0.3.18\n","language_data                      1.3.0\n","launchpadlib                       1.10.16\n","lazr.restfulclient                 0.14.4\n","lazr.uri                           1.0.6\n","lazy_loader                        0.4\n","libclang                           18.1.1\n","libcudf-cu12                       25.2.1\n","libcugraph-cu12                    25.2.0\n","libcuml-cu12                       25.2.1\n","libcuvs-cu12                       25.2.1\n","libkvikio-cu12                     25.2.1\n","libraft-cu12                       25.2.0\n","librosa                            0.11.0\n","libucx-cu12                        1.18.0\n","libucxx-cu12                       0.42.0\n","lightgbm                           4.5.0\n","lightning-utilities                0.14.2\n","linkify-it-py                      2.0.3\n","llvmlite                           0.43.0\n","locket                             1.0.0\n","logical-unification                0.4.6\n","loguru                             0.7.3\n","lxml                               5.3.1\n","Mako                               1.1.3\n","marisa-trie                        1.2.1\n","Markdown                           3.7\n","markdown-it-py                     3.0.0\n","MarkupSafe                         3.0.2\n","matplotlib                         3.10.0\n","matplotlib-inline                  0.1.7\n","matplotlib-venn                    1.1.2\n","mdit-py-plugins                    0.4.2\n","mdurl                              0.1.2\n","miniKanren                         1.0.3\n","missingno                          0.5.2\n","mistune                            3.1.3\n","mizani                             0.13.1\n","mkl                                2025.0.1\n","ml-dtypes                          0.4.1\n","mlxtend                            0.23.4\n","more-itertools                     10.6.0\n","moviepy                            1.0.3\n","mpmath                             1.3.0\n","msgpack                            1.1.0\n","multidict                          6.2.0\n","multipledispatch                   1.0.0\n","multiprocess                       0.70.16\n","multitasking                       0.0.11\n","multivolumefile                    0.2.3\n","murmurhash                         1.0.12\n","music21                            9.3.0\n","namex                              0.0.8\n","narwhals                           1.31.0\n","natsort                            8.4.0\n","nbclassic                          1.2.0\n","nbclient                           0.10.2\n","nbconvert                          7.16.6\n","nbformat                           5.10.4\n","ndindex                            1.9.2\n","nest-asyncio                       1.6.0\n","networkx                           3.4.2\n","nibabel                            5.3.2\n","nltk                               3.9.1\n","notebook                           6.5.7\n","notebook_shim                      0.2.4\n","numba                              0.60.0\n","numba-cuda                         0.2.0\n","numexpr                            2.10.2\n","numpy                              2.0.2\n","nvidia-cublas-cu12                 12.4.5.8\n","nvidia-cuda-cupti-cu12             12.4.127\n","nvidia-cuda-nvcc-cu12              12.5.82\n","nvidia-cuda-nvrtc-cu12             12.4.127\n","nvidia-cuda-runtime-cu12           12.4.127\n","nvidia-cudnn-cu12                  9.1.0.70\n","nvidia-cufft-cu12                  11.2.1.3\n","nvidia-curand-cu12                 10.3.5.147\n","nvidia-cusolver-cu12               11.6.1.9\n","nvidia-cusparse-cu12               12.3.1.170\n","nvidia-cusparselt-cu12             0.6.2\n","nvidia-ml-py                       12.535.161\n","nvidia-nccl-cu12                   2.21.5\n","nvidia-nvcomp-cu12                 4.2.0.11\n","nvidia-nvjitlink-cu12              12.4.127\n","nvidia-nvtx-cu12                   12.4.127\n","nvitop                             1.3.2\n","nvtx                               0.2.11\n","nx-cugraph-cu12                    25.2.0\n","oauth2client                       4.1.3\n","oauthlib                           3.2.2\n","openai                             1.68.2\n","opencv-contrib-python              4.11.0.86\n","opencv-python                      4.11.0.86\n","opencv-python-headless             4.11.0.86\n","openpyxl                           3.1.5\n","opentelemetry-api                  1.31.1\n","opentelemetry-sdk                  1.31.1\n","opentelemetry-semantic-conventions 0.52b1\n","opt_einsum                         3.4.0\n","optax                              0.2.4\n","optree                             0.14.1\n","optuna                             4.1.0\n","orbax-checkpoint                   0.11.10\n","orjson                             3.10.15\n","osqp                               0.6.7.post3\n","packaging                          24.2\n","pandas                             2.2.3\n","pandas-datareader                  0.10.0\n","pandas-gbq                         0.28.0\n","pandas-stubs                       2.2.2.240909\n","pandocfilters                      1.5.1\n","panel                              1.6.1\n","param                              2.2.0\n","parso                              0.8.4\n","parsy                              2.1\n","partd                              1.4.2\n","pathlib                            1.0.1\n","patsy                              1.0.1\n","peewee                             3.17.9\n","peft                               0.14.0\n","pexpect                            4.9.0\n","pickleshare                        0.7.5\n","pillow                             11.0.0\n","pip                                24.1.2\n","platformdirs                       4.3.7\n","plotly                             5.24.1\n","plotnine                           0.14.5\n","pluggy                             1.5.0\n","ply                                3.11\n","polars                             1.21.0\n","pooch                              1.8.2\n","portpicker                         1.5.2\n","preshed                            3.0.9\n","prettytable                        3.15.1\n","proglog                            0.1.10\n","progressbar2                       4.5.0\n","prometheus_client                  0.21.1\n","promise                            2.3\n","prompt_toolkit                     3.0.50\n","propcache                          0.3.0\n","prophet                            1.1.6\n","proto-plus                         1.26.1\n","protobuf                           5.29.4\n","psutil                             5.9.5\n","psycopg2                           2.9.10\n","ptyprocess                         0.7.0\n","py-cpuinfo                         9.0.0\n","py4j                               0.10.9.7\n","py7zr                              0.22.0\n","pyarrow                            18.1.0\n","pyasn1                             0.6.1\n","pyasn1_modules                     0.4.1\n","pybcj                              1.0.3\n","pycairo                            1.27.0\n","pycocotools                        2.0.8\n","pycparser                          2.22\n","pycryptodomex                      3.22.0\n","pydantic                           2.10.4\n","pydantic_core                      2.27.2\n","pydata-google-auth                 1.9.1\n","pydot                              3.0.4\n","pydotplus                          2.0.2\n","PyDrive                            1.3.1\n","PyDrive2                           1.21.3\n","pyerfa                             2.0.1.5\n","pygame                             2.6.1\n","pygit2                             1.17.0\n","Pygments                           2.18.0\n","PyGObject                          3.42.0\n","PyJWT                              2.10.1\n","pylibcudf-cu12                     25.2.1\n","pylibcugraph-cu12                  25.2.0\n","pylibraft-cu12                     25.2.0\n","pymc                               5.21.1\n","pymystem3                          0.2.0\n","pyngrok                            7.2.1\n","pynndescent                        0.5.13\n","pynvjitlink-cu12                   0.5.2\n","pynvml                             12.0.0\n","pyogrio                            0.10.0\n","Pyomo                              6.8.2\n","PyOpenGL                           3.1.9\n","pyOpenSSL                          24.2.1\n","pyparsing                          3.2.1\n","pyperclip                          1.9.0\n","pyppmd                             1.1.1\n","pyproj                             3.7.1\n","pyshp                              2.3.1\n","PySocks                            1.7.1\n","pyspark                            3.5.5\n","pytensor                           2.28.3\n","pytest                             8.3.5\n","python-apt                         0.0.0\n","python-box                         7.3.2\n","python-dateutil                    2.8.2\n","python-louvain                     0.16\n","python-multipart                   0.0.20\n","python-slugify                     8.0.4\n","python-snappy                      0.7.3\n","python-utils                       3.9.1\n","pytz                               2025.1\n","pyviz_comms                        3.0.4\n","PyYAML                             6.0.2\n","pyzmq                              24.0.1\n","pyzstd                             0.16.2\n","qdldl                              0.1.7.post5\n","raft-dask-cu12                     25.2.0\n","RapidFuzz                          3.12.2\n","rapids-dask-dependency             25.2.0\n","ratelim                            0.1.6\n","referencing                        0.36.2\n","regex                              2024.11.6\n","requests                           2.32.3\n","requests-oauthlib                  2.0.0\n","requests-toolbelt                  1.0.0\n","requirements-parser                0.9.0\n","rich                               13.9.4\n","rmm-cu12                           25.2.0\n","roman-numerals-py                  3.1.0\n","rouge_score                        0.1.2\n","rpds-py                            0.23.1\n","rpy2                               3.5.17\n","rsa                                4.9\n","sacremoses                         0.1.1\n","safetensors                        0.5.3\n","scikit-image                       0.25.2\n","scikit-learn                       1.6.0\n","scipy                              1.14.1\n","scooby                             0.10.0\n","scs                                3.2.7.post2\n","seaborn                            0.13.2\n","SecretStorage                      3.3.1\n","Send2Trash                         1.8.3\n","sentence-transformers              3.3.1\n","sentencepiece                      0.2.0\n","sentry-sdk                         2.24.0\n","seqeval                            1.2.2\n","setproctitle                       1.3.5\n","setuptools                         75.1.0\n","shap                               0.47.0\n","shapely                            2.0.7\n","shellingham                        1.5.4\n","simple-parsing                     0.1.7\n","simplejson                         3.20.1\n","simsimd                            6.2.1\n","six                                1.17.0\n","sklearn-compat                     0.1.3\n","sklearn-pandas                     2.2.0\n","slicer                             0.0.8\n","smart-open                         7.1.0\n","smmap                              5.0.2\n","sniffio                            1.3.1\n","snowballstemmer                    2.2.0\n","sortedcontainers                   2.4.0\n","soundfile                          0.13.1\n","soupsieve                          2.6\n","soxr                               0.5.0.post1\n","spacy                              3.8.4\n","spacy-legacy                       3.0.12\n","spacy-loggers                      1.0.5\n","spanner-graph-notebook             1.1.5\n","Sphinx                             8.2.3\n","sphinxcontrib-applehelp            2.0.0\n","sphinxcontrib-devhelp              2.0.0\n","sphinxcontrib-htmlhelp             2.1.0\n","sphinxcontrib-jsmath               1.0.1\n","sphinxcontrib-qthelp               2.0.0\n","sphinxcontrib-serializinghtml      2.0.0\n","SQLAlchemy                         2.0.39\n","sqlglot                            25.20.2\n","sqlparse                           0.5.3\n","srsly                              2.5.1\n","stanio                             0.5.1\n","starlette                          0.41.3\n","statsmodels                        0.14.4\n","stringzilla                        3.12.3\n","sympy                              1.13.1\n","tables                             3.10.2\n","tabulate                           0.9.0\n","tbb                                2022.1.0\n","tblib                              3.0.0\n","tcmlib                             1.3.0\n","tenacity                           9.0.0\n","tensorboard                        2.18.0\n","tensorboard-data-server            0.7.2\n","tensorflow                         2.18.0\n","tensorflow-datasets                4.9.8\n","tensorflow-hub                     0.16.1\n","tensorflow-io-gcs-filesystem       0.37.1\n","tensorflow-metadata                1.16.1\n","tensorflow-probability             0.25.0\n","tensorflow-text                    2.18.1\n","tensorstore                        0.1.72\n","termcolor                          2.5.0\n","terminado                          0.18.1\n","text-unidecode                     1.3\n","textblob                           0.19.0\n","texttable                          1.7.0\n","tf_keras                           2.18.0\n","tf-slim                            1.1.0\n","thinc                              8.3.4\n","threadpoolctl                      3.6.0\n","tifffile                           2025.3.13\n","tiktoken                           0.8.0\n","timm                               1.0.12\n","tinycss2                           1.4.0\n","tokenizers                         0.21.1\n","toml                               0.10.2\n","toolz                              0.12.1\n","torch                              2.6.0+cu124\n","torchaudio                         2.6.0+cu124\n","torchmetrics                       1.6.0\n","torchsummary                       1.5.1\n","torchvision                        0.21.0+cu124\n","tornado                            6.4.2\n","tqdm                               4.67.1\n","traitlets                          5.7.1\n","traittypes                         0.2.1\n","transformers                       4.48.0\n","treelite                           4.4.1\n","treescope                          0.1.9\n","triton                             2.1.0\n","trl                                0.13.0\n","tweepy                             4.15.0\n","typeguard                          4.4.2\n","typer                              0.15.2\n","types-pytz                         2025.1.0.20250318\n","types-setuptools                   76.0.0.20250313\n","typing_extensions                  4.12.2\n","tzdata                             2025.1\n","tzlocal                            5.3.1\n","uc-micro-py                        1.0.3\n","ucx-py-cu12                        0.42.0\n","ucxx-cu12                          0.42.0\n","umap-learn                         0.5.7\n","umf                                0.10.0\n","uritemplate                        4.1.1\n","urllib3                            2.3.0\n","uvicorn                            0.34.0\n","vega-datasets                      0.9.0\n","wadllib                            1.3.6\n","wandb                              0.19.8\n","wasabi                             1.1.3\n","wcwidth                            0.2.13\n","weasel                             0.4.1\n","webcolors                          24.11.1\n","webencodings                       0.5.1\n","websocket-client                   1.8.0\n","websockets                         15.0.1\n","Werkzeug                           3.1.3\n","wheel                              0.45.1\n","widgetsnbextension                 3.6.10\n","wordcloud                          1.9.4\n","wrapt                              1.17.2\n","xarray                             2025.1.2\n","xarray-einstats                    0.8.0\n","xgboost                            2.1.3\n","xlrd                               2.0.1\n","xxhash                             3.5.0\n","xyzservices                        2025.1.0\n","yarl                               1.18.3\n","yellowbrick                        1.5\n","yfinance                           0.2.55\n","zict                               3.0.0\n","zipp                               3.21.0\n","zstandard                          0.23.0\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17364,"status":"ok","timestamp":1743249517649,"user":{"displayName":"재환김","userId":"10617165991486556387"},"user_tz":-540},"id":"r6shEqYoOJ7q","outputId":"7ed45b1f-f865-44db-e2fa-117041780320"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# 1. 모델과 토크나이저 로드\n","from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n","import torch\n","\n","# 모델은 이미 NF4 양자화 되어있음!\n","model_path = \"/content/drive/MyDrive/ProjectSummarizer/quantized_model\"\n","\n","# 4비트 양자화 설정\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.float16,\n","    bnb_4bit_use_double_quant=False,\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_path,\n","    quantization_config=bnb_config,\n","    device_map={\"\": 0} # GPU 0번에 모델 로드 (환경에 맞게 조절)\n",")\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","tokenizer.pad_token = tokenizer.eos_token # 패딩 토큰 설정 (필요한 경우)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["d18da17cf13a49e0aedde0616822945a","fca7065db05d4728a085065fd8399465","6751b561b46340c293de149e00de7de1","78d294b5f94c4c368dd769a9914cc136","e5d7145412664d1ba792c4de44e2bdd5","90ac18dd34a545eda2feb5f46fa6702b","2149b19e9cd5431ab86be86a43271824","ffb071d8ee4c4e23b8b1d1946743698e","53e007fd13444d46ab72a7240a5ba3f7","b750ce6b3e344a8ca85ad45ba03dd6be","65d527e5209d40f7a7ade68b12edf560"]},"id":"p22jH1qFs9wC","executionInfo":{"status":"ok","timestamp":1743250542617,"user_tz":-540,"elapsed":28940,"user":{"displayName":"재환김","userId":"10617165991486556387"}},"outputId":"6b059375-929a-4311-d598-4bdac5949331"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n","/usr/local/lib/python3.11/dist-packages/transformers/quantizers/auto.py:195: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n","  warnings.warn(warning_msg)\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d18da17cf13a49e0aedde0616822945a"}},"metadata":{}}]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":527,"referenced_widgets":["35751bde456741f09b7385df8ce0305e","7ebadcdc67c7411b86e547cdd5f1b9a5","d8ba2095bf8a4d0598e2a7b31b2ee287","ecc2be37cd4247a29b4227283e847c2d","195d01d71f4f4d17bed0ccb34b6eccc7","e19c3799bc3f4b27bd363ae0dc4e6a0a","51c05445c20d4844b7bf11ab5c394ee3","1ed95a065038450d87f76a75439517d3","7b50ea435396435c92a18f42ebc853c5","211a294584fd49f28c33ebc149c3aefa","b91a03ec4afa4b1b99e5e8d0fa341f73","8df09c3a2bb84fbc9020934af5b1f461","ecc7fce680ca45c4a7eb891f854d9082","baee74db08d645a1a27d3da8eeec8139","1af96b4146854275ae7c4b6df1896a05","ea8a05603c03403d85acfc606af2f2f1","7a93af2821914b44986459bb2e22e39c","ab6e38e9dcae4ac7857275893af8dc7d","4c7d5b6d0e8d4b1485a74516e1a2ba4a","63f69cae6b92427eabf938cf356408b9","3438eb93df6e454883cf616a2c0abf66","b794c27b273a460193bed36e5881515d"]},"executionInfo":{"elapsed":52365,"status":"error","timestamp":1743250142246,"user":{"displayName":"재환김","userId":"10617165991486556387"},"user_tz":-540},"id":"NDoLRg9WseHN","outputId":"059d7984-2574-4c66-81e9-3a634bd4b77c"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35751bde456741f09b7385df8ce0305e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['messages'],\n","    num_rows: 73431\n","})\n","{'messages': [{'content': '다음을 요약하세요.', 'role': 'system'}, {'content': '조선 전기에 활동했던 관리로서 중종 때 청백리로 널리 알려진 우재 손중돈(1463∼1529)의 옛집이다. 언덕에 자리잡은 건물들의 배치는 사랑채와 안채가 ㅁ자형을 이루는데, 가운데의 마당을 중심으로 남쪽에는 사랑채, 나머지는 안채로 구성된다. 안채의 동북쪽에는 사당을 배치하고, 담으로 양쪽 옆면과 뒷면을 둘러 막아, 집의 앞쪽을 탁 트이게 하여 낮은 지대의 경치를 바라볼 수 있게 하였다. 보통 대문은 행랑채와 연결되지만, 이 집은 특이하게 대문이 사랑채와 연결되어 있다. 사랑채는 남자주인이 생활하면서 손님들을 맞이하는 공간으로, 대문의 왼쪽에 사랑방과 마루가 있다. 마루는 앞면이 트여있는 누마루로 ‘관가정(觀稼亭)’ 이라는 현판이 걸려있다. 대문의 오른쪽에는 온돌방, 부엌, 작은방들을 두었고 그 앞에 ㄷ자로 꺾이는 안채가 있다. 안채는 안주인이 살림을 하는 공간으로, 부엌, 안방, 큰 대청마루, 광으로 구성되어 있으며 사랑채의 사랑방과 연결이 된다. 네모기둥을 세우고 간소한 모습을 하고 있으나, 뒤쪽의 사당과 누마루는 둥근기둥을 세워 조금은 웅장한 느낌이 들게 했다. 사랑방과 누마루 주변으로는 난간을 돌렸고, 지붕은 안채와 사랑채가 한 지붕으로 이어져 있다. 관가정은 조선 중기의 남부지방 주택을 연구하는데 귀중한 자료가 되는 문화재이다.', 'role': 'user'}, {'content': '손중돈의 옛집은 특이하게 대문이 사랑채와 연결되어 있으며 마루는 앞면이 트여있는 누마루다. 보통 대문은 행랑채와 연결되지만, 이 집은 특이하게 대문이 사랑채와 연결되어 있다. 조선 전기에 활동했던 관리로서 중종 때 청백리로 널리 알려진 우재 손중돈(1463∼1529)의 옛집이다. 마루는 앞면이 트여있는 누마루로 ‘관가정(觀稼亭)’ 이라는 현판이 걸려있다.', 'role': 'assistant'}]}\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/73431 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8df09c3a2bb84fbc9020934af5b1f461"}},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-dd08ae81f8fe>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mtokenized_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[1;32m    884\u001b[0m             \u001b[0mcache_file_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         return DatasetDict(\n\u001b[0;32m--> 886\u001b[0;31m             {\n\u001b[0m\u001b[1;32m    887\u001b[0m                 k: dataset.map(\n\u001b[1;32m    888\u001b[0m                     \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    885\u001b[0m         return DatasetDict(\n\u001b[1;32m    886\u001b[0m             {\n\u001b[0;32m--> 887\u001b[0;31m                 k: dataset.map(\n\u001b[0m\u001b[1;32m    888\u001b[0m                     \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m                     \u001b[0mwith_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwith_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m         }\n\u001b[1;32m    559\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3071\u001b[0m                     \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"Map\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3072\u001b[0m                 ) as pbar:\n\u001b[0;32m-> 3073\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdataset_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3074\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m                             \u001b[0mshards_done\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3497\u001b[0m                                 \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_arrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3498\u001b[0m                             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3499\u001b[0;31m                                 \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3500\u001b[0m                         \u001b[0mnum_examples_progress_update\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnum_examples_in_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3501\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_time\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPBAR_REFRESH_TIME_INTERVAL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/arrow_writer.py\u001b[0m in \u001b[0;36mwrite_batch\u001b[0;34m(self, batch_examples, writer_batch_size)\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0mcol_try_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtry_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtry_features\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtry_features\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m                 \u001b[0mtyped_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptimizedTypedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol_try_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m                 \u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyped_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m                 \u001b[0minferred_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtyped_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_inferred_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minferred_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrow_schema\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpa_writer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._handle_arrow_array_protocol\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/arrow_writer.py\u001b[0m in \u001b[0;36m__arrow_array__\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0mtrying_cast_to_python_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to_python_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_1d_for_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m             \u001b[0;31m# use smaller integer precisions if possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrying_int_optimization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# 2. 데이터셋 준비, 그리고 전처리\n","\n","from datasets import load_dataset\n","\n","dataset_path = \"/content/drive/MyDrive/ProjectSummarizer/dataset/train.json\"\n","dataset = load_dataset(\"json\", data_files=dataset_path)\n","\n","\n","print(dataset[\"train\"])\n","# \"messages\" feature를 \"conversations\"로 이름 변경\n","# dataset = dataset.rename_column(\"messages\", \"conversations\")\n","# # 변경된 Dataset 확인\n","# print(dataset)\n","print(dataset[\"train\"][0])  # 첫 번째 샘플 출력\n","\n","\n","# 전처리 함수 정의\n","def preprocess_function(examples):\n","    inputs = []\n","    for conversations in examples['messages']:\n","        inputs.append(tokenizer.apply_chat_template(conversations, tokenize=False))\n","    model_inputs = tokenizer(inputs, max_length=1024, truncation=True, padding=\"max_length\")\n","    labels = model_inputs[\"input_ids\"].copy()\n","    model_inputs[\"labels\"] = labels  # 'labels' 키를 model_inputs에 추가\n","    return model_inputs\n","\n","tokenized_dataset = dataset.map(preprocess_function, batched=True)\n","print(tokenized_dataset)\n","print(tokenized_dataset['train'][0])"]},{"cell_type":"code","source":["# 3. lora(qlora) 모델 선언\n","from peft import LoraConfig, get_peft_model\n","\n","lora_config = LoraConfig(\n","    r=16, # LoRA 레이어의 rank (조정 가능)\n","    lora_alpha=32, # 스케일링 파라미터 (조정 가능)\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\"\n",")\n","\n","model = get_peft_model(model, lora_config)\n","model.print_trainable_parameters() # 학습 가능한 파라미터 수 확인"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N1XSUtFlvucx","executionInfo":{"status":"ok","timestamp":1743224795437,"user_tz":-540,"elapsed":438,"user":{"displayName":"재환김","userId":"10617165991486556387"}},"outputId":"e2fc0677-155e-4357-c825-10ffc8d5fbc4"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["trainable params: 6,815,744 || all params: 8,037,076,992 || trainable%: 0.0848\n"]}]},{"cell_type":"code","source":["# 4. 학습 매개변수 설정\n","from transformers import TrainingArguments\n","\n","output_dir = \"/content/drive/MyDrive/ProjectSummarizer/checkpoint\"\n","training_args = TrainingArguments(\n","    output_dir=output_dir,\n","    learning_rate=2e-4,\n","    per_device_train_batch_size=4,\n","    num_train_epochs=3,\n","    warmup_ratio=0.1,\n","    weight_decay=0.01,\n","    fp16=True,\n","    gradient_accumulation_steps=8,\n","    save_steps=500,  # 500 스텝마다 저장\n","    save_total_limit=1,\n","    logging_dir=\"./logs\",\n","    save_strategy=\"steps\", # 스텝 단위로 저장하도록 변경\n","    resume_from_checkpoint=True, # 저장된 체크포인트가 있으면 읽어서 다시 시작\n","    push_to_hub=False,\n","    report_to=\"none\", # wandb의 영향력 제거\n",")"],"metadata":{"id":"GT2mmpHVwnf9","executionInfo":{"status":"ok","timestamp":1743225195800,"user_tz":-540,"elapsed":23,"user":{"displayName":"재환김","userId":"10617165991486556387"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"7Fkc3AVbUA1Y","executionInfo":{"status":"ok","timestamp":1743250510210,"user_tz":-540,"elapsed":29,"user":{"displayName":"재환김","userId":"10617165991486556387"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["from transformers import Trainer\n","import torch\n","\n","trainer = Trainer(\n","    model=model,\n","    train_dataset=tokenized_dataset['train'],\n","    args=training_args,\n","    data_collator=lambda data: {\n","        'input_ids': torch.tensor([f['input_ids'] for f in data]),\n","        'attention_mask': torch.tensor([f['attention_mask'] for f in data]),\n","        'labels': torch.tensor([f['labels'] for f in data])\n","    }\n",")\n","\n","trainer.train()\n","\n","# 학습된 모델 저장\n","model.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":603},"id":"rq8fz0FJyC4X","executionInfo":{"status":"error","timestamp":1743249063821,"user_tz":-540,"elapsed":23865134,"user":{"displayName":"재환김","userId":"10617165991486556387"}},"outputId":"d94c2b04-bd01-423e-f49b-ffb55e3bd4ab"},"execution_count":37,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3125' max='6882' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3125/6882 6:37:29 < 7:58:10, 0.13 it/s, Epoch 1.36/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>12.698700</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>10.221500</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>10.001000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>9.812000</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>9.697600</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>9.657700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-16366b3e27e4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# 학습된 모델 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2170\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2171\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2172\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2173\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2529\u001b[0m                     )\n\u001b[1;32m   2530\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2531\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2533\u001b[0m                     if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3713\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3715\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3717\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2242\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2243\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2244\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2245\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_lomo_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2246\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# 6. 추론전 결합\n","from peft import PeftModel\n","\n","qlora_path = \"/content/drive/MyDrive/ProjectSummarizer/checkpoint/checkpoint-3000\"  # QLoRA 학습 모델 경로\n","model = PeftModel.from_pretrained(model, qlora_path)\n","\n","# eval도 해야하나?"],"metadata":{"id":"VJuR2eOj4IAY","executionInfo":{"status":"ok","timestamp":1743250570158,"user_tz":-540,"elapsed":260,"user":{"displayName":"재환김","userId":"10617165991486556387"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# 7. 추론\n","PROMPT = '''다음을 요약하세요.'''\n","instruction = '''네, 산청 산불 지휘 본부에 나와 있습니다.\n","헬기 진화는 해가 지면서 중단됐고요.\n","지금은 지상 인력 약 1천 명이 투입돼 밤샘 진화 작업에 들어갔습니다.\n","오후 한때 빗방울이 잠시 떨어지기도 했지만, 금방 그쳤습니다.\n","경남 산청과 하동 전체 진화율은 오후 6시 기준 99%까지 올랐습니다.\n","오늘은 아침부터 기상 상황이 좋아 일찌감치 헬기 진화가 시작됐습니다.\n","진화 헬기 49대가 주불이 있는 지리산 내원계곡 일대에 집중 투입돼 진화 작업을 벌였습니다.\n","진화대와 소방, 경찰 군인 등 약 1천6백 명과 살수차와 동물방역기를 비롯한 각종 장비 2백여 대가 투입됐습니다.\n","한때 천왕봉 4.5km까지 근접했던 산불을 지난밤 밤샘 진화 작업을 벌여 내원계곡 쪽으로 약 2km 후퇴시켰고, 오늘 오후엔 진화율을 99%까지 끌어올렸습니다.\n","이제 남은 불의 길이는 4백 미텁니다.\n","다만 지리산은 숲이 우거져 헬기로 물을 뿌려도 지표면에 잘 닿지 않고, 계곡에 쌓인 낙엽은 깊이가 1m가 넘습니다.\n","위에서 물을 뿌려 불을 끄기도 쉽지 않고 낙엽층 속에 숨어있던 불은 번번이 되살아납니다.\n","지리산국립공원의 산불 영향구역은 이미 132ha에 이릅니다.\n","진화율 99%까지 왔지만 아직 긴장을 늦출 수 없는 이유입니다.\n","하동 산불지역에선 뒷불 감시와 잔불 정리를 계속 하고 있습니다.\n","오늘 아침 한때 바람 방향이 바뀌면서 산청군 삼장면 신촌마을 등 5개 마을에 다시 주민 대피령이 내려지기도 했습니다.\n","산청과 하동 주민 460여 명은 아직 대피소에 머물고 있는 상태입니다.\n","지금까지 산청 산불 현장에서 MBC뉴스 이재경입니다.'''\n","\n","messages = [\n","    {\"role\": \"system\", \"content\": f\"{PROMPT}\"},\n","    {\"role\": \"user\", \"content\": f\"{instruction}\"}\n","]\n","\n","# 메시지를 템플릿 형식으로 적용\n","prompt = tokenizer.apply_chat_template(\n","    messages,\n","    tokenize=False,\n","    add_generation_prompt=True\n",")\n","\n","# 종료 조건 정의\n","terminators = [\n","    tokenizer.eos_token_id,\n","    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n","]\n","\n","inputs = tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n","\n","# 모델을 통해 텍스트 생성\n","with torch.no_grad():\n","    outputs = model.generate(\n","        input_ids=inputs['input_ids'],  # input_ids 전달\n","        attention_mask=inputs.get('attention_mask', None),  # attention_mask가 있을 경우 전달\n","        max_new_tokens=1024,            # 생성할 최대 토큰 수\n","        eos_token_id=tokenizer.eos_token_id,  # 종료 토큰 설정\n","        do_sample=True,                 # 샘플링 방식 사용\n","        temperature=0.6,                # 창의성 조절\n","        top_p=0.9,                      # 확률 분포 상위 p 비율에 해당하는 후보만 선택\n","        pad_token_id=tokenizer.pad_token_id  # 패딩 토큰 ID (필요시 설정)\n","    )\n","\n","# 생성된 텍스트 디코딩\n","generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","print('------')\n","# 출력 결과에서 프롬프트 부분 제외하고 결과 출력\n","print(generated_text)\n","print('------')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9xPGQ1_q20dP","executionInfo":{"status":"ok","timestamp":1743252679048,"user_tz":-540,"elapsed":14807,"user":{"displayName":"재환김","userId":"10617165991486556387"}},"outputId":"c094767e-0b45-42a4-ec53-fd2308b420cc"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["------\n","system\n","\n","다음을 요약하세요.user\n","\n","네, 산청 산불 지휘 본부에 나와 있습니다.\n","헬기 진화는 해가 지면서 중단됐고요.\n","지금은 지상 인력 약 1천 명이 투입돼 밤샘 진화 작업에 들어갔습니다.\n","오후 한때 빗방울이 잠시 떨어지기도 했지만, 금방 그쳤습니다.\n","경남 산청과 하동 전체 진화율은 오후 6시 기준 99%까지 올랐습니다.\n","오늘은 아침부터 기상 상황이 좋아 일찌감치 헬기 진화가 시작됐습니다.\n","진화 헬기 49대가 주불이 있는 지리산 내원계곡 일대에 집중 투입돼 진화 작업을 벌였습니다.\n","진화대와 소방, 경찰 군인 등 약 1천6백 명과 살수차와 동물방역기를 비롯한 각종 장비 2백여 대가 투입됐습니다.\n","한때 천왕봉 4.5km까지 근접했던 산불을 지난밤 밤샘 진화 작업을 벌여 내원계곡 쪽으로 약 2km 후퇴시켰고, 오늘 오후엔 진화율을 99%까지 끌어올렸습니다.\n","이제 남은 불의 길이는 4백 미텁니다.\n","다만 지리산은 숲이 우거져 헬기로 물을 뿌려도 지표면에 잘 닿지 않고, 계곡에 쌓인 낙엽은 깊이가 1m가 넘습니다.\n","위에서 물을 뿌려 불을 끄기도 쉽지 않고 낙엽층 속에 숨어있던 불은 번번이 되살아납니다.\n","지리산국립공원의 산불 영향구역은 이미 132ha에 이릅니다.\n","진화율 99%까지 왔지만 아직 긴장을 늦출 수 없는 이유입니다.\n","하동 산불지역에선 뒷불 감시와 잔불 정리를 계속 하고 있습니다.\n","오늘 아침 한때 바람 방향이 바뀌면서 산청군 삼장면 신촌마을 등 5개 마을에 다시 주민 대피령이 내려지기도 했습니다.\n","산청과 하동 주민 460여 명은 아직 대피소에 머물고 있는 상태입니다.\n","지금까지 산청 산불 현장에서 MBC뉴스 이재경입니다.assistant\n","\n","지리산국립공원의 산불 영향구역은 132ha에 이르렀고 진화율이 99%까지 왔지만 아직 긴장을 늦출 수 없는 이유로 하동 산불지역에선 잔불 정리를 계속하고 있다. 지리산국립공원의 산불 영향구역은 이미 132ha에 이릅니다. 진화율 99%까지 왔지만 아직 긴장을 늦출 수 없는 이유입니다. 하동 산불지역에선 뒷불 감시와 잔불 정리를 계속 하고 있습니다.\n","------\n"]}]},{"cell_type":"code","source":["while True:\n","    # 사용자로부터 입력 받기\n","    instruction = input(\"입력하실 내용을 입력하세요 (종료하려면 'exit' 입력): \")\n","\n","    if instruction.lower() == 'exit':\n","        print(\"프로그램을 종료합니다.\")\n","        break  # 'exit'을 입력하면 반복문 종료\n","\n","    # 메시지를 템플릿 형식으로 적용\n","    messages = [\n","        {\"role\": \"system\", \"content\": f\"{PROMPT}\"},\n","        {\"role\": \"user\", \"content\": f\"{instruction}\"}\n","    ]\n","\n","    # 메시지를 템플릿 형식으로 적용\n","    prompt = tokenizer.apply_chat_template(\n","        messages,\n","        tokenize=False,\n","        add_generation_prompt=True\n","    )\n","\n","    # 종료 조건 정의\n","    terminators = [\n","        tokenizer.eos_token_id,\n","        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n","    ]\n","\n","    # inputs를 device로 이동\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n","\n","    # 모델을 통해 텍스트 생성\n","    with torch.no_grad():\n","        outputs = model.generate(\n","            input_ids=inputs['input_ids'],  # input_ids 전달\n","            attention_mask=inputs.get('attention_mask', None),  # attention_mask가 있을 경우 전달\n","            max_new_tokens=1024,            # 생성할 최대 토큰 수\n","            eos_token_id=tokenizer.eos_token_id,  # 종료 토큰 설정\n","            do_sample=True,                 # 샘플링 방식 사용\n","            temperature=0.6,                # 창의성 조절\n","            top_p=0.9,                      # 확률 분포 상위 p 비율에 해당하는 후보만 선택\n","            pad_token_id=tokenizer.pad_token_id  # 패딩 토큰 ID (필요시 설정)\n","        )\n","\n","    # 생성된 텍스트 디코딩\n","    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","    # 출력 결과에서 프롬프트 부분 제외하고 결과 출력\n","    print('------')\n","    print(generated_text)\n","    print('------')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":723},"id":"xyspheL59Llb","executionInfo":{"status":"error","timestamp":1743253118332,"user_tz":-540,"elapsed":351473,"user":{"displayName":"재환김","userId":"10617165991486556387"}},"outputId":"f47d54a2-d48b-4139-b7a0-7a3281292095"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["입력하실 내용을 입력하세요 (종료하려면 'exit' 입력): 1. 탄핵소추사유는 그 대상 사실을 다른 사실과 명백하게 구분할 수 있을 정도의 구체적 사실이 기재되면 충분하다. 이 사건 소추의결서의 헌법 위배행위 부분은 소추사유가 분명하게 유형별로 구분되지 않은 측면이 있지만, 소추사유로 기재된 사실관계는 법률 위배행위 부분과 함께 보면 다른 소추사유와 명백하게 구분할 수 있을 정도로 충분히 구체적으로 기재되어 있다. 2. 가. 국회의 의사절차에 헌법이나 법률을 명백히 위반한 흠이 있는 경우가 아니면 국회 의사절차의 자율권은 권력분립의 원칙상 존중되어야 하고, 국회법 제130조 제1항은 탄핵소추의 발의가 있을 때 그 사유 등에 대한 조사 여부를 국회의 재량으로 규정하고 있으므로, 국회가 탄핵소추사유에 대하여 별도의 조사를 하지 않았다거나 국정조사결과나 특별검사의 수사결과를 기다리지 않고 탄핵소추안을 의결하였다고 하여 그 의결이 헌법이나 법률을 위반한 것이라고 볼 수 없다. 나. 국회법에 탄핵소추안에 대하여 표결 전에 반드시 토론을 거쳐야 한다는 명문 규정은 없다. 또 이 사건 소추의결 당시 토론을 희망한 의원이 없었기 때문에 탄핵소추안에 대한 제안 설명만 듣고 토론 없이 표결이 이루어졌을 뿐, 의장이 토론을 희망하는 의원이 있었는데도 토론을 못하게 하거나 방해한 사실은 없다. 다. 탄핵소추안을 각 소추사유별로 나누어 발의할 것인지, 아니면 여러 소추사유를 포함하여 하나의 안으로 발의할 것인지는 소추안을 발의하는 의원들의 자유로운 의사에 달린 것이고, 표결방법에 관한 어떠한 명문규정도 없다. 라. 탄핵소추절차는 국회와 대통령이라는 헌법기관 사이의 문제이고, 국회의 탄핵소추의결에 따라 사인으로서 대통령 개인의 기본권이 침해되는 것이 아니다. 국가기관이 국민에 대하여 공권력을 행사할 때 준수하여야 하는 법원칙으로 형성된 적법절차의 원칙을 국가기관에 대하여 헌법을 수호하고자 하는 탄핵소추절차에 직접 적용할 수 없다. 3. 헌법재판은 9인의 재판관으로 구성된 재판부에 의하여 이루어지는 것이 원칙이다. 그러나 현실적으로는 일부 재판관이 재판에 참여할 수 없는 경우가 발생할 수밖에 없다. 이에 헌법과 헌법재판소법은 재판관 중 결원이 발생한 경우에도 헌법재판소의 헌법 수호 기능이 중단되지 않도록 7명 이상의 재판관이 출석하면 사건을 심리하고 결정할 수 있음을 분명히 하고 있다. 그렇다면 헌법재판관 1인이 결원이 되어 8인의 재판관으로 재판부가 구성되더라도 탄핵심판을 심리하고 결정하는 데 헌법과 법률상 아무런 문제가 없다.\n","------\n","system\n","\n","다음을 요약하세요.user\n","\n","1. 탄핵소추사유는 그 대상 사실을 다른 사실과 명백하게 구분할 수 있을 정도의 구체적 사실이 기재되면 충분하다. 이 사건 소추의결서의 헌법 위배행위 부분은 소추사유가 분명하게 유형별로 구분되지 않은 측면이 있지만, 소추사유로 기재된 사실관계는 법률 위배행위 부분과 함께 보면 다른 소추사유와 명백하게 구분할 수 있을 정도로 충분히 구체적으로 기재되어 있다. 2. 가. 국회의 의사절차에 헌법이나 법률을 명백히 위반한 흠이 있는 경우가 아니면 국회 의사절차의 자율권은 권력분립의 원칙상 존중되어야 하고, 국회법 제130조 제1항은 탄핵소추의 발의가 있을 때 그 사유 등에 대한 조사 여부를 국회의 재량으로 규정하고 있으므로, 국회가 탄핵소추사유에 대하여 별도의 조사를 하지 않았다거나 국정조사결과나 특별검사의 수사결과를 기다리지 않고 탄핵소추안을 의결하였다고 하여 그 의결이 헌법이나 법률을 위반한 것이라고 볼 수 없다. 나. 국회법에 탄핵소추안에 대하여 표결 전에 반드시 토론을 거쳐야 한다는 명문 규정은 없다. 또 이 사건 소추의결 당시 토론을 희망한 의원이 없었기 때문에 탄핵소추안에 대한 제안 설명만 듣고 토론 없이 표결이 이루어졌을 뿐, 의장이 토론을 희망하는 의원이 있었는데도 토론을 못하게 하거나 방해한 사실은 없다. 다. 탄핵소추안을 각 소추사유별로 나누어 발의할 것인지, 아니면 여러 소추사유를 포함하여 하나의 안으로 발의할 것인지는 소추안을 발의하는 의원들의 자유로운 의사에 달린 것이고, 표결방법에 관한 어떠한 명문규정도 없다. 라. 탄핵소추절차는 국회와 대통령이라는 헌법기관 사이의 문제이고, 국회의 탄핵소추의결에 따라 사인으로서 대통령 개인의 기본권이 침해되는 것이 아니다. 국가기관이 국민에 대하여 공권력을 행사할 때 준수하여야 하는 법원칙으로 형성된 적법절차의 원칙을 국가기관에 대하여 헌법을 수호하고자 하는 탄핵소추절차에 직접 적용할 수 없다. 3. 헌법재판은 9인의 재판관으로 구성된 재판부에 의하여 이루어지는 것이 원칙이다. 그러나 현실적으로는 일부 재판관이 재판에 참여할 수 없는 경우가 발생할 수밖에 없다. 이에 헌법과 헌법재판소법은 재판관 중 결원이 발생한 경우에도 헌법재판소의 헌법 수호 기능이 중단되지 않도록 7명 이상의 재판관이 출석하면 사건을 심리하고 결정할 수 있음을 분명히 하고 있다. 그렇다면 헌법재판관 1인이 결원이 되어 8인의 재판관으로 재판부가 구성되더라도 탄핵심판을 심리하고 결정하는 데 헌법과 법률상 아무런 문제가 없다.assistant\n","\n","탄핵소추사유가 분명하게 유형별로 구분되지 않은 측면이 있지만 법률 위배행위 부분과 함께 보면 충분히 구체적으로 기재되어 있다. 1. 탄핵소추사유는 그 대상 사실을 다른 사실과 명백하게 구분할 수 있을 정도의 구체적 사실이 기재되면 충분하다. 이 사건 소추의결서의 헌법 위배행위 부분은 소추사유가 분명하게 유형별로 구분되지 않은 측면이 있지만, 소추사유로 기재된 사실관계는 법률 위배행위 부분과 함께 보면 다른 소추사유와 명백하게 구분할 수 있을 정도로 충분히 구체적으로 기재되어 있다.\n","------\n","입력하실 내용을 입력하세요 (종료하려면 'exit' 입력): 건의 주신 부분에 대해서 사실 다 좋은 말씀입니다. 잘못됐다는 얘기는 아니고 말씀이 나온 김에, 그 김에, 나온 계기에 한번 얘길 해 보자. 원칙이라는 거… 말이지요. 상호주의, 거기에 대칭되는 원칙은 뭘까요? 일방주의 아니겠습니까? 문법상 그렇습니다. 근데 참여정부의, 상호주의에 대응하는 참여정부의 정책은 실용주의입니다. 왜냐면 상호주의라는 것은 형식적이고 경직된 원칙이 될 수 있습니다. 남북 관계를 해 가는 데 조건이 다르고 서로 처지가 너무 다른데, 생각도 다르고 다른데, 이거 상호주의 해서, 어떤 분이 말씀하는 것처럼 \"니가 한 대 때리면 나도 한 대 때리고, 이게 상호주의 아니겄소?\" 간단하게 그렇게 뭐 얘기할 수 있지만 남북 관계 그렇게 간단한 것은 아닙니다. 결국 우리가 추구자… 추구하고 하고자 하는 목표, 평화, 신뢰, 뭐 이런 그 목적에 맞느냐, 맞지 않느냐를 놓고 그때그때 우리가 판단해야지, 그냥 상호주의라는 이런 원칙에 묶어 두면 안 된다 이렇게 생각합니다. 결코 일방주의적 퍼 주기를 하지, 하는 것이 아니라 장기적인 목표를 놓고 신뢰를 확보하고, 결국은 남북 간에 대화로써 보다 큰 목표를 달성할 때까지 어떻게 하는 것이 더 유익하냐, 그래서 실용주의, 상호주의에 대응하는 정책 개념은 실용주의라고 이해해 주십시오.\n","------\n","system\n","\n","다음을 요약하세요.user\n","\n","건의 주신 부분에 대해서 사실 다 좋은 말씀입니다. 잘못됐다는 얘기는 아니고 말씀이 나온 김에, 그 김에, 나온 계기에 한번 얘길 해 보자. 원칙이라는 거… 말이지요. 상호주의, 거기에 대칭되는 원칙은 뭘까요? 일방주의 아니겠습니까? 문법상 그렇습니다. 근데 참여정부의, 상호주의에 대응하는 참여정부의 정책은 실용주의입니다. 왜냐면 상호주의라는 것은 형식적이고 경직된 원칙이 될 수 있습니다. 남북 관계를 해 가는 데 조건이 다르고 서로 처지가 너무 다른데, 생각도 다르고 다른데, 이거 상호주의 해서, 어떤 분이 말씀하는 것처럼 \"니가 한 대 때리면 나도 한 대 때리고, 이게 상호주의 아니겄소?\" 간단하게 그렇게 뭐 얘기할 수 있지만 남북 관계 그렇게 간단한 것은 아닙니다. 결국 우리가 추구자… 추구하고 하고자 하는 목표, 평화, 신뢰, 뭐 이런 그 목적에 맞느냐, 맞지 않느냐를 놓고 그때그때 우리가 판단해야지, 그냥 상호주의라는 이런 원칙에 묶어 두면 안 된다 이렇게 생각합니다. 결코 일방주의적 퍼 주기를 하지, 하는 것이 아니라 장기적인 목표를 놓고 신뢰를 확보하고, 결국은 남북 간에 대화로써 보다 큰 목표를 달성할 때까지 어떻게 하는 것이 더 유익하냐, 그래서 실용주의, 상호주의에 대응하는 정책 개념은 실용주의라고 이해해 주십시오.assistant\n","\n","상호주의는 형식적이고 경직된 원칙이 될 수 있기 때문에 남북 관계를 해 가는 데 조건이 다르고 처지가 다른데 상호주의라는 것은 간단하게 얘기할 수 있지만 남북 관계는 그렇게 간단하지 않다. 왜냐면 상호주의라는 것은 형식적이고 경직된 원칙이 될 수 있습니다. 남북 관계를 해 가는 데 조건이 다르고 서로 처지가 너무 다른데, 생각도 다르고 다른데, 이거 상호주의 해서, 어떤 분이 말씀하는 것처럼 \"니가 한 대 때리면 나도 한 대 때리고, 이게 상호주의 아니겄소?\" 간단하게 그렇게 뭐 얘기할 수 있지만 남북 관계 그렇게 간단한 것은 아닙니다.\n","------\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"Interrupted by user","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-f0a6bb6e4704>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# 사용자로부터 입력 받기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0minstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"입력하실 내용을 입력하세요 (종료하려면 'exit' 입력): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minstruction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12270,"status":"ok","timestamp":1742997382351,"user":{"displayName":"김재환","userId":"12736849163701558078"},"user_tz":-540},"id":"6G_8XA2SxR4d","outputId":"6e03fc1e-a750-4ec8-8f26-f54b30c1fb0f"},"outputs":[{"output_type":"stream","name":"stdout","text":["usage: autotrain <command> [<args>] llm [-h] [--train] [--deploy] [--inference]\n","                                        [--backend BACKEND] [--model MODEL]\n","                                        [--project-name PROJECT_NAME] [--data-path DATA_PATH]\n","                                        [--train-split TRAIN_SPLIT] [--valid-split VALID_SPLIT]\n","                                        [--add-eos-token] [--model-max-length MODEL_MAX_LENGTH]\n","                                        [--padding PADDING] [--trainer TRAINER]\n","                                        [--use-flash-attention-2] [--log LOG]\n","                                        [--disable-gradient-checkpointing]\n","                                        [--logging-steps LOGGING_STEPS]\n","                                        [--eval-strategy EVAL_STRATEGY]\n","                                        [--save-total-limit SAVE_TOTAL_LIMIT]\n","                                        [--auto-find-batch-size]\n","                                        [--mixed-precision MIXED_PRECISION] [--lr LR]\n","                                        [--epochs EPOCHS] [--batch-size BATCH_SIZE]\n","                                        [--warmup-ratio WARMUP_RATIO]\n","                                        [--gradient-accumulation GRADIENT_ACCUMULATION]\n","                                        [--optimizer OPTIMIZER] [--scheduler SCHEDULER]\n","                                        [--weight-decay WEIGHT_DECAY]\n","                                        [--max-grad-norm MAX_GRAD_NORM] [--seed SEED]\n","                                        [--chat-template CHAT_TEMPLATE]\n","                                        [--quantization QUANTIZATION]\n","                                        [--target-modules TARGET_MODULES] [--merge-adapter]\n","                                        [--peft] [--lora-r LORA_R] [--lora-alpha LORA_ALPHA]\n","                                        [--lora-dropout LORA_DROPOUT] [--model-ref MODEL_REF]\n","                                        [--dpo-beta DPO_BETA]\n","                                        [--max-prompt-length MAX_PROMPT_LENGTH]\n","                                        [--max-completion-length MAX_COMPLETION_LENGTH]\n","                                        [--prompt-text-column PROMPT_TEXT_COLUMN]\n","                                        [--text-column TEXT_COLUMN]\n","                                        [--rejected-text-column REJECTED_TEXT_COLUMN]\n","                                        [--push-to-hub] [--username USERNAME] [--token TOKEN]\n","                                        [--unsloth] [--distributed-backend DISTRIBUTED_BACKEND]\n","                                        [--block_size BLOCK_SIZE]\n","\n","✨ Run AutoTrain LLM\n","\n","options:\n","  -h, --help            show this help message and exit\n","  --train               Command to train the model\n","  --deploy              Command to deploy the model (limited availability)\n","  --inference           Command to run inference (limited availability)\n","  --backend BACKEND     Backend\n","  --model MODEL, --model MODEL, --model MODEL\n","                        Model name to be used for training\n","  --project-name PROJECT_NAME, --project_name PROJECT_NAME, --project-name PROJECT_NAME\n","                        Name of the project and output directory\n","  --data-path DATA_PATH, --data_path DATA_PATH, --data-path DATA_PATH\n","                        Path to the dataset\n","  --train-split TRAIN_SPLIT, --train_split TRAIN_SPLIT, --train-split TRAIN_SPLIT\n","                        Configuration for the training data split\n","  --valid-split VALID_SPLIT, --valid_split VALID_SPLIT, --valid-split VALID_SPLIT\n","                        Configuration for the validation data split\n","  --add-eos-token, --add_eos_token, --add-eos-token\n","                        Whether to add an EOS token at the end of sequences\n","  --model-max-length MODEL_MAX_LENGTH, --model_max_length MODEL_MAX_LENGTH, --model-max-length MODEL_MAX_LENGTH\n","                        Maximum length of the model input\n","  --padding PADDING, --padding PADDING, --padding PADDING\n","                        Side on which to pad sequences (left or right)\n","  --trainer TRAINER, --trainer TRAINER, --trainer TRAINER\n","                        Type of trainer to use\n","  --use-flash-attention-2, --use_flash_attention_2, --use-flash-attention-2\n","                        Whether to use flash attention version 2\n","  --log LOG, --log LOG, --log LOG\n","                        Logging method for experiment tracking\n","  --disable-gradient-checkpointing, --disable_gradient_checkpointing, --disable-gradient-checkpointing\n","                        Whether to disable gradient checkpointing\n","  --logging-steps LOGGING_STEPS, --logging_steps LOGGING_STEPS, --logging-steps LOGGING_STEPS\n","                        Number of steps between logging events\n","  --eval-strategy EVAL_STRATEGY, --eval_strategy EVAL_STRATEGY, --eval-strategy EVAL_STRATEGY\n","                        Strategy for evaluation (e.g., 'epoch')\n","  --save-total-limit SAVE_TOTAL_LIMIT, --save_total_limit SAVE_TOTAL_LIMIT, --save-total-limit SAVE_TOTAL_LIMIT\n","                        Maximum number of checkpoints to keep\n","  --auto-find-batch-size, --auto_find_batch_size, --auto-find-batch-size\n","                        Whether to automatically find the optimal batch size\n","  --mixed-precision MIXED_PRECISION, --mixed_precision MIXED_PRECISION, --mixed-precision MIXED_PRECISION\n","                        Type of mixed precision to use (e.g., 'fp16', 'bf16', or None)\n","  --lr LR, --lr LR, --lr LR\n","                        Learning rate for training\n","  --epochs EPOCHS, --epochs EPOCHS, --epochs EPOCHS\n","                        Number of training epochs\n","  --batch-size BATCH_SIZE, --batch_size BATCH_SIZE, --batch-size BATCH_SIZE\n","                        Batch size for training\n","  --warmup-ratio WARMUP_RATIO, --warmup_ratio WARMUP_RATIO, --warmup-ratio WARMUP_RATIO\n","                        Proportion of training to perform learning rate warmup\n","  --gradient-accumulation GRADIENT_ACCUMULATION, --gradient_accumulation GRADIENT_ACCUMULATION, --gradient-accumulation GRADIENT_ACCUMULATION\n","                        Number of steps to accumulate gradients before updating\n","  --optimizer OPTIMIZER, --optimizer OPTIMIZER, --optimizer OPTIMIZER\n","                        Optimizer to use for training\n","  --scheduler SCHEDULER, --scheduler SCHEDULER, --scheduler SCHEDULER\n","                        Learning rate scheduler to use\n","  --weight-decay WEIGHT_DECAY, --weight_decay WEIGHT_DECAY, --weight-decay WEIGHT_DECAY\n","                        Weight decay to apply to the optimizer\n","  --max-grad-norm MAX_GRAD_NORM, --max_grad_norm MAX_GRAD_NORM, --max-grad-norm MAX_GRAD_NORM\n","                        Maximum norm for gradient clipping\n","  --seed SEED, --seed SEED, --seed SEED\n","                        Random seed for reproducibility\n","  --chat-template CHAT_TEMPLATE, --chat_template CHAT_TEMPLATE, --chat-template CHAT_TEMPLATE\n","                        Template for chat-based models, options include: None, zephyr, chatml, or\n","                        tokenizer\n","  --quantization QUANTIZATION, --quantization QUANTIZATION, --quantization QUANTIZATION\n","                        Quantization method to use (e.g., 'int4', 'int8', or None)\n","  --target-modules TARGET_MODULES, --target_modules TARGET_MODULES, --target-modules TARGET_MODULES\n","                        Target modules for quantization or fine-tuning\n","  --merge-adapter, --merge_adapter, --merge-adapter\n","                        Whether to merge the adapter layers\n","  --peft, --peft, --peft\n","                        Whether to use Parameter-Efficient Fine-Tuning (PEFT)\n","  --lora-r LORA_R, --lora_r LORA_R, --lora-r LORA_R\n","                        Rank of the LoRA matrices\n","  --lora-alpha LORA_ALPHA, --lora_alpha LORA_ALPHA, --lora-alpha LORA_ALPHA\n","                        Alpha parameter for LoRA\n","  --lora-dropout LORA_DROPOUT, --lora_dropout LORA_DROPOUT, --lora-dropout LORA_DROPOUT\n","                        Dropout rate for LoRA\n","  --model-ref MODEL_REF, --model_ref MODEL_REF, --model-ref MODEL_REF\n","                        Reference model for DPO trainer\n","  --dpo-beta DPO_BETA, --dpo_beta DPO_BETA, --dpo-beta DPO_BETA\n","                        Beta parameter for DPO trainer\n","  --max-prompt-length MAX_PROMPT_LENGTH, --max_prompt_length MAX_PROMPT_LENGTH, --max-prompt-length MAX_PROMPT_LENGTH\n","                        Maximum length of the prompt\n","  --max-completion-length MAX_COMPLETION_LENGTH, --max_completion_length MAX_COMPLETION_LENGTH, --max-completion-length MAX_COMPLETION_LENGTH\n","                        Maximum length of the completion\n","  --prompt-text-column PROMPT_TEXT_COLUMN, --prompt_text_column PROMPT_TEXT_COLUMN, --prompt-text-column PROMPT_TEXT_COLUMN\n","                        Column name for the prompt text\n","  --text-column TEXT_COLUMN, --text_column TEXT_COLUMN, --text-column TEXT_COLUMN\n","                        Column name for the text data\n","  --rejected-text-column REJECTED_TEXT_COLUMN, --rejected_text_column REJECTED_TEXT_COLUMN, --rejected-text-column REJECTED_TEXT_COLUMN\n","                        Column name for the rejected text data\n","  --push-to-hub, --push_to_hub, --push-to-hub\n","                        Whether to push the model to the Hugging Face Hub\n","  --username USERNAME, --username USERNAME, --username USERNAME\n","                        Hugging Face username for authentication\n","  --token TOKEN, --token TOKEN, --token TOKEN\n","                        Hugging Face token for authentication\n","  --unsloth, --unsloth, --unsloth\n","                        Whether to use the unsloth library\n","  --distributed-backend DISTRIBUTED_BACKEND, --distributed_backend DISTRIBUTED_BACKEND, --distributed-backend DISTRIBUTED_BACKEND\n","                        Backend to use for distributed training\n","  --block_size BLOCK_SIZE, --block-size BLOCK_SIZE\n","                        Block size\n"]}],"source":["!autotrain llm -help"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SwLBuKklI7r-","executionInfo":{"status":"ok","timestamp":1742999331981,"user_tz":-540,"elapsed":248279,"user":{"displayName":"김재환","userId":"12736849163701558078"}},"outputId":"573af3b0-c9d6-4241-a063-fbb7a6f328f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-26 14:24:52\u001b[0m | \u001b[36mautotrain.cli.run_llm\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1mRunning LLM\u001b[0m\n","\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2025-03-26 14:24:52\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m286\u001b[0m - \u001b[33m\u001b[1mParameters supplied but not used: train, func, inference, backend, version, config, deploy\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-26 14:24:52\u001b[0m | \u001b[36mautotrain.backends.local\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-26 14:24:52\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m514\u001b[0m - \u001b[1m['accelerate', 'launch', '--num_machines', '1', '--num_processes', '1', '--mixed_precision', 'fp16', '-m', 'autotrain.trainers.clm', '--training_config', 'qlora-finetuned/training_params.json']\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-26 14:24:52\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m515\u001b[0m - \u001b[1m{'model': '/content/drive/MyDrive/ProjectSummarizer/quantized_model', 'project_name': 'qlora-finetuned', 'data_path': '/content/drive/MyDrive/ProjectSummarizer/dataset/', 'train_split': 'train', 'valid_split': None, 'add_eos_token': True, 'block_size': 1024, 'model_max_length': 2048, 'padding': 'right', 'trainer': 'sft', 'use_flash_attention_2': False, 'log': 'none', 'disable_gradient_checkpointing': False, 'logging_steps': -1, 'eval_strategy': 'epoch', 'save_total_limit': 1, 'auto_find_batch_size': False, 'mixed_precision': 'fp16', 'lr': 0.0002, 'epochs': 1, 'batch_size': 2, 'warmup_ratio': 0.1, 'gradient_accumulation': 8, 'optimizer': 'adamw_torch', 'scheduler': 'linear', 'weight_decay': 0.01, 'max_grad_norm': 1.0, 'seed': 42, 'chat_template': None, 'quantization': 'int4', 'target_modules': 'all-linear', 'merge_adapter': False, 'peft': True, 'lora_r': 16, 'lora_alpha': 32, 'lora_dropout': 0.05, 'model_ref': None, 'dpo_beta': 0.1, 'max_prompt_length': 128, 'max_completion_length': None, 'prompt_text_column': None, 'text_column': 'messages', 'rejected_text_column': None, 'push_to_hub': False, 'username': None, 'token': None, 'unsloth': False, 'distributed_backend': None}\u001b[0m\n","The following values were not passed to `accelerate launch` and had defaults used instead:\n","\t`--dynamo_backend` was set to a value of `'no'`\n","To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1742999107.402084   20280 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1742999107.412107   20280 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-26 14:25:12\u001b[0m | \u001b[36mautotrain.trainers.clm.train_clm_sft\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mStarting SFT training...\u001b[0m\n","Generating train split: 73431 examples [00:06, 11241.26 examples/s]\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-26 14:25:19\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m550\u001b[0m - \u001b[1mTrain data: Dataset({\n","    features: ['messages'],\n","    num_rows: 73431\n","})\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-26 14:25:19\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1mValid data: None\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-26 14:25:19\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mconfigure_logging_steps\u001b[0m:\u001b[36m671\u001b[0m - \u001b[1mconfiguring logging steps\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-26 14:25:19\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mconfigure_logging_steps\u001b[0m:\u001b[36m684\u001b[0m - \u001b[1mLogging steps: 25\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-26 14:25:19\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mconfigure_training_args\u001b[0m:\u001b[36m723\u001b[0m - \u001b[1mconfiguring training args\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-26 14:25:19\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mconfigure_block_size\u001b[0m:\u001b[36m801\u001b[0m - \u001b[1mUsing block size 1024\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-26 14:25:19\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mget_model\u001b[0m:\u001b[36m877\u001b[0m - \u001b[1mCan use unsloth: False\u001b[0m\n","\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2025-03-26 14:25:19\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mget_model\u001b[0m:\u001b[36m919\u001b[0m - \u001b[33m\u001b[1mUnsloth not available, continuing without it...\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-26 14:25:19\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mget_model\u001b[0m:\u001b[36m921\u001b[0m - \u001b[1mloading model config...\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-26 14:25:19\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mget_model\u001b[0m:\u001b[36m929\u001b[0m - \u001b[1mloading model...\u001b[0m\n","Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n","`low_cpu_mem_usage` was None, now default to True since model is quantized.\n","Loading checkpoint shards: 100% 2/2 [00:40<00:00, 20.49s/it]\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-26 14:26:01\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mget_model\u001b[0m:\u001b[36m960\u001b[0m - \u001b[1mmodel dtype: torch.float16\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-26 14:26:01\u001b[0m | \u001b[36mautotrain.trainers.clm.train_clm_sft\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mcreating trainer\u001b[0m\n","Generating train split: 50422 examples [02:41, 312.61 examples/s]\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-26 14:28:44\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_train_begin\u001b[0m:\u001b[36m386\u001b[0m - \u001b[1mStarting to train...\u001b[0m\n","  0% 0/3151 [00:00<?, ?it/s]\u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[32m2025-03-26 14:28:47\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mwrapper\u001b[0m:\u001b[36m215\u001b[0m - \u001b[31m\u001b[1mtrain has failed due to an exception: Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/autotrain/trainers/common.py\", line 212, in wrapper\n","    return func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/autotrain/trainers/clm/__main__.py\", line 28, in train\n","    train_sft(config)\n","  File \"/usr/local/lib/python3.11/dist-packages/autotrain/trainers/clm/train_clm_sft.py\", line 55, in train\n","    trainer.train()\n","  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2171, in train\n","    return inner_training_loop(\n","           ^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2531, in _inner_training_loop\n","    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 3676, in training_step\n","    loss = self.compute_loss(model, inputs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 3734, in compute_loss\n","    outputs = model(**inputs)\n","              ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\", line 823, in forward\n","    return model_forward(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\", line 811, in __call__\n","    return convert_to_fp32(self.model_forward(*args, **kwargs))\n","                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py\", line 44, in decorate_autocast\n","    return func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/peft/peft_model.py\", line 1719, in forward\n","    return self.base_model(\n","           ^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py\", line 197, in forward\n","    return self.model.forward(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 831, in forward\n","    outputs = self.model(\n","              ^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 577, in forward\n","    layer_outputs = self._gradient_checkpointing_func(\n","                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/_compile.py\", line 32, in inner\n","    return disable_fn(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\", line 745, in _fn\n","    return fn(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py\", line 489, in checkpoint\n","    return CheckpointFunction.apply(function, preserve, *args)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/function.py\", line 575, in apply\n","    return super().apply(*args, **kwargs)  # type: ignore[misc]\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py\", line 264, in forward\n","    outputs = run_function(*args)\n","              ^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 348, in forward\n","    hidden_states = self.mlp(hidden_states)\n","                    ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 186, in forward\n","    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n","                                                                ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/bnb.py\", line 496, in forward\n","    result = self.base_layer(x, *args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/bitsandbytes/nn/modules.py\", line 484, in forward\n","    return bnb.matmul_4bit(x, self.weight.t(), bias=bias, quant_state=self.weight.quant_state).to(inp_dtype)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py\", line 533, in matmul_4bit\n","    return MatMul4Bit.apply(A, B, out, bias, quant_state)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/function.py\", line 575, in apply\n","    return super().apply(*args, **kwargs)  # type: ignore[misc]\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py\", line 462, in forward\n","    output = torch.nn.functional.linear(A, F.dequantize_4bit(B, quant_state).to(A.dtype).t(), bias)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 46.12 MiB is free. Process 17989 has 5.36 GiB memory in use. Process 282208 has 9.34 GiB memory in use. Of the allocated memory 8.71 GiB is allocated by PyTorch, and 517.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","\u001b[0m\n","\u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[32m2025-03-26 14:28:47\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mwrapper\u001b[0m:\u001b[36m216\u001b[0m - \u001b[31m\u001b[1mCUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 46.12 MiB is free. Process 17989 has 5.36 GiB memory in use. Process 282208 has 9.34 GiB memory in use. Of the allocated memory 8.71 GiB is allocated by PyTorch, and 517.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\u001b[0m\n","  0% 0/3151 [00:03<?, ?it/s]\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-26 14:28:50\u001b[0m | \u001b[36mautotrain.cli.run_llm\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m141\u001b[0m - \u001b[1mJob ID: 20234\u001b[0m\n"]}],"source":["# --gradient-accumulation 4 \\\n","\n","base_model = '/content/drive/MyDrive/ProjectSummarizer/quantized_model'\n","finetuned_model = 'qlora-finetuned'\n","data_path = '/content/drive/MyDrive/ProjectSummarizer/dataset/'\n","checkpoint_path = \"/content/drive/MyDrive/ProjectSummarizer/checkpoint\"\n","\n","!autotrain llm \\\n","--train \\\n","--model {base_model} \\\n","--project-name {finetuned_model} \\\n","--text-column \"messages\" \\\n","--data-path {data_path} \\\n","--lr 2e-4 \\\n","--batch-size 2 \\\n","--epochs 1 \\\n","--block-size 1024 \\\n","--warmup-ratio 0.1 \\\n","--lora-r 16 \\\n","--lora-alpha 32 \\\n","--lora-dropout 0.05 \\\n","--weight-decay 0.01 \\\n","--mixed-precision fp16 \\\n","--gradient-accumulation 8 \\\n","--peft \\\n","--quantization int4 \\\n","--trainer sft \\\n","--save-total-limit 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1742891423081,"user":{"displayName":"김재환","userId":"12736849163701558078"},"user_tz":-540},"id":"dBOnsTYlaL_V","outputId":"aba6d19a-6e63-4cd8-cb66-748d63a0d341"},"outputs":[{"name":"stdout","output_type":"stream","text":["총 문장 수: 22\n","각 문장의 토큰 수: [26, 22, 56, 73, 16, 32, 9, 46, 89, 39, 36, 18, 37, 37, 31, 24, 21, 58, 20, 14, 31, 32]\n","767\n"]}],"source":["# 토크나이저 작동 방식\n","def count_sentences_and_tokens(text, tokenizer):\n","    import re\n","\n","    # 문장 분리 (간단한 문장 분리기)\n","    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n","\n","    # 각 문장의 토큰 수 계산\n","    sentence_token_counts = [len(tokenizer.tokenize(sentence)) for sentence in sentences]\n","\n","    return len(sentences), sentence_token_counts\n","\n","# 테스트할 텍스트\n","text = \"세계 스마트폰 생산량 중 중국에서 생산하는 비중이 지난해 70% 밑으로 떨어졌다.   스마트폰업체들이 생산 기지를 중국에서 다른 지역으로 옮기고 있기 때문이다.   더욱이 신종 코로나바이러스 감염증(코로나19) 사태로 ‘중국 공급망 리스크’가 부각되면서 스마트폰업체들의 탈(脫)중국 행렬이 거세질 것으로 보인다.      중국은…임금 상승, 미·중 분쟁, 코로나까지   25일 시장조사업체인 카운터포인트리서치에 따르면, 지난해 전 세계 스마트폰 생산량 중 중국에서 생산된 비중은 전년(72%)보다 줄어든 68%인 것으로 나타났다.   2016년에는 75%, 이듬해에는 74%였다.   카운터포인트리서치는 \\\"중국이 세계 스마트폰 공장으로서의 매력을 잃고 있다\\\"고 분석했다.   이유는 크게 세 가지다.   중국 근로자의 인건비 상승, 미·중 무역분쟁 여파, 그리고 인도 등 스마트폰 판매량이 급증하고 있는 신흥시장의 부상이다.   중국 대체할 생산기지로 인도·베트남 급부상  카운터포인트리서치는 \\\"특히 인도가 '메이크 인 인디아(make in IIndia)' 정책을 펴며 스마트폰업체를 유인하고 있다\\\"며 \\\"세계에서 두 번째 큰 시장으로 성장한 인도의 정책에 많은 업체가 동요하고 있다\\\"고 전했다.   인도는 '메이크 인 인디아'라는 자국 산업 육성정책에 따라 전기·전자 부품 관련 수입 관세를 급격히 높였다.   무관세였던 휴대전화 완제품과 부품을 인도로 들여가려면 15~20%의 관세를 내야 한다.   인도에서 팔 스마트폰은 인도에서 만들라는 메시지다.   또 베트남도 중국 대비 저렴한 인건비와 각종 개혁개방 정책을 무기로 스마트폰 공장 유치에 적극적이다.     삼성전자는 완전 철수, 애플도 인도 이전 추진 중   탈(脫) 중국의 대표적인 업체가 삼성전자다.   삼성전자는 2018년 톈진 공장을, 지난해 9월에는 후이저우 공장을 폐쇄했다.   적어도 스마트폰의 생산공장만큼은 중국에서 완전히 철수한 셈이다.   인건비 상승과 중국 내수 시장 점유율 급락이 주된 이유다.   스마트폰 업계에 따르면 삼성전자 중국 공장의 근로자 월평균 급여가 2008년 274달러(약 34만원)에서 2018년에는 832달러(104만원)로 3배 증가했다.   또 삼성전자의 중국 스마트폰 시장 점유율은 2013년 19.  7%에서 최근엔 1% 밑으로 떨어졌다.   삼성전자는 이제 스마트폰을 베트남 박닌·타이응우엔과 인도 노이다 등에서 생산하고 있다.   아이폰의 90% 이상을 위탁 생산하는 폭스콘과 페가트론도 일부 생산 라인을 인도 등으로 이전했다. \"\n","\n","num_sentences, token_counts = count_sentences_and_tokens(text, pipeline.tokenizer)\n","\n","print(f\"총 문장 수: {num_sentences}\")\n","print(f\"각 문장의 토큰 수: {token_counts}\")\n","print(sum(token_counts))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":505,"referenced_widgets":["259bf81ba57044b39ad355ecf9c2c2d7","6d1a0a275a7b46238a1378c7debeeb21","b8abde4a903743ccaa7bea88119ba467","c6b8c4bf075b4ca38bd97f3e4d1cfa80","575e330313ea429f9a717917a361aa8a","fd3a22a2ab1346f6a9ef030c11c54310","b6074c08ebf04fee81dbbba753c78c66","a4535ac5a73e4a8188a1d87afbd82683","c3789d24d92b46c988be74652796d3da","768fcf4b6e894478867740d8c1a8684e","7d5dc12aee8f414cba77e1dfe9847a56"]},"id":"iGITr1A1XVgN","outputId":"25bc3ac5-d7bd-46df-e480-ce5e1a2b6d23","executionInfo":{"status":"error","timestamp":1743080441597,"user_tz":-540,"elapsed":91112,"user":{"displayName":"김재환","userId":"12736849163701558078"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"259bf81ba57044b39ad355ecf9c2c2d7"}},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-c69898834a98>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 텍스트 생성 파이프라인 초기화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m pipeline = transformers.pipeline(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;34m\"text-generation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# 모델 경로를 지정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mframework\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0mmodel_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m         framework, model = infer_framework_load_model(\n\u001b[0m\u001b[1;32m    941\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0mmodel_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"eval\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    565\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4222\u001b[0m                     \u001b[0moffload_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4223\u001b[0m                     \u001b[0merror_msgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4224\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4225\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4226\u001b[0m                     \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path, weights_only)\u001b[0m\n\u001b[1;32m   4792\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4793\u001b[0m                         \u001b[0mfixed_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fix_state_dict_keys_on_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4794\u001b[0;31m                         new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(\n\u001b[0m\u001b[1;32m   4795\u001b[0m                             \u001b[0mmodel_to_load\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4796\u001b[0m                             \u001b[0mfixed_state_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys, pretrained_model_name_or_path)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# For backward compatibility with older versions of `accelerate` and for non-quantized params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0mset_module_tensor_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mset_module_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0mhf_quantizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_quantized_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/modeling.py\u001b[0m in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mold_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import transformers\n","import torch\n","\n","# 모델이 저장된 경로\n","model_path = \"/content/drive/MyDrive/ProjectSummarizer/quantized_model\"\n","\n","# 텍스트 생성 파이프라인 초기화\n","pipeline = transformers.pipeline(\n","    \"text-generation\",\n","    model=model_path,  # 모델 경로를 지정\n","    model_kwargs={\n","        \"device_map\": \"auto\",  # GPU 또는 CPU 자동 매핑\n","    }\n",")\n","\n","pipeline.model.eval()\n","\n","PROMPT = '''당신은 인간과 대화하는 친절한 챗봇입니다. 질문에 대한 정보를 상황에 맞게 자세히 제공합니다. 당신이 질문에 대한 답을 모른다면, 사실은 모른다고 말합니다.'''\n","instruction = \"복잡도 이론에서 PH는 무엇인가요?\"\n","\n","messages = [\n","    {\"role\": \"system\", \"content\": f\"{PROMPT}\"},\n","    {\"role\": \"user\", \"content\": f\"{instruction}\"}\n","]\n","# messages = [\n","#     {\"role\": \"system\", \"content\": f\"{PROMPT}\"},\n","#     {\"role\": \"user\", \"content\": f\"{instruction}\"}\n","# ]\n","\n","\n","# 메시지를 템플릿 형식으로 적용\n","prompt = pipeline.tokenizer.apply_chat_template(\n","    messages,\n","    tokenize=False,\n","    add_generation_prompt=True\n",")\n","\n","# 종료 조건 정의\n","terminators = [\n","    pipeline.tokenizer.eos_token_id,\n","    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n","]\n","\n","# 텍스트 생성\n","outputs = pipeline(\n","    prompt,\n","    max_new_tokens=2048,\n","    eos_token_id=terminators,\n","    do_sample=True,\n","    temperature=0.6,\n","    top_p=0.9\n",")\n","\n","# 출력 결과에서 프롬프트 부분 제외하고 결과 출력\n","print(outputs[0][\"generated_text\"][len(prompt):])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":110,"status":"ok","timestamp":1742892706130,"user":{"displayName":"김재환","userId":"12736849163701558078"},"user_tz":-540},"id":"pG_KuW6Hbp00","outputId":"6a3bb980-9318-4ce5-c998-29a66345e921"},"outputs":[{"name":"stdout","output_type":"stream","text":["/bin/bash: line 1: nvidia-smi: command not found\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kvtyRerf4mmW","outputId":"e6fae8ff-3b19-40d8-eb30-c36086ce5ef5"},"outputs":[{"name":"stdout","output_type":"stream","text":["반복 질문을 시작합니다. 'exit'를 입력하면 종료됩니다.\n","Enter your instruction: 네 이름은 뭐지\n","\n","Generated Response:\n","네, 저는 \"챗봇\"입니다.\n","--------------------------------------------------\n"]}],"source":["# 사용자로부터 instruction을 반복적으로 입력받아 모델에 전달\n","print(\"반복 질문을 시작합니다. 'exit'를 입력하면 종료됩니다.\")\n","\n","while True:\n","    # 사용자로부터 질문 입력받기\n","    instruction = input(\"Enter your instruction: \")\n","\n","    # 'exit'를 입력하면 종료\n","    if instruction.lower() == \"exit\":\n","        print(\"종료합니다. 감사합니다!\")\n","        break\n","\n","    # 메시지 구성\n","    messages = [\n","        {\"role\": \"system\", \"content\": '''당신은 인간과 대화하는 친절한 챗봇입니다. 질문에 대한 정보를 상황에 맞게 자세히 제공합니다. 당신이 질문에 대한 답을 모른다면, 사실은 모른다고 말합니다.'''},\n","        {\"role\": \"user\", \"content\": instruction}\n","    ]\n","\n","    # 프롬프트 생성\n","    prompt = pipeline.tokenizer.apply_chat_template(\n","        messages,\n","        tokenize=False,\n","        add_generation_prompt=True\n","    )\n","\n","    # 텍스트 생성\n","    terminators = [\n","        pipeline.tokenizer.eos_token_id,\n","        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n","    ]\n","\n","    outputs = pipeline(\n","        prompt,\n","        max_new_tokens=2048,\n","        eos_token_id=terminators,\n","        do_sample=True,\n","        temperature=0.6,\n","        top_p=0.9\n","    )\n","\n","    # 출력 결과\n","    generated_text = outputs[0][\"generated_text\"][len(prompt):]\n","    print(\"\\nGenerated Response:\")\n","    print(generated_text)\n","    print(\"-\" * 50)  # 출력 구분선\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"259bf81ba57044b39ad355ecf9c2c2d7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6d1a0a275a7b46238a1378c7debeeb21","IPY_MODEL_b8abde4a903743ccaa7bea88119ba467","IPY_MODEL_c6b8c4bf075b4ca38bd97f3e4d1cfa80"],"layout":"IPY_MODEL_575e330313ea429f9a717917a361aa8a"}},"6d1a0a275a7b46238a1378c7debeeb21":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd3a22a2ab1346f6a9ef030c11c54310","placeholder":"​","style":"IPY_MODEL_b6074c08ebf04fee81dbbba753c78c66","value":"Loading checkpoint shards:   0%"}},"b8abde4a903743ccaa7bea88119ba467":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4535ac5a73e4a8188a1d87afbd82683","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c3789d24d92b46c988be74652796d3da","value":0}},"c6b8c4bf075b4ca38bd97f3e4d1cfa80":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_768fcf4b6e894478867740d8c1a8684e","placeholder":"​","style":"IPY_MODEL_7d5dc12aee8f414cba77e1dfe9847a56","value":" 0/2 [01:03&lt;?, ?it/s]"}},"575e330313ea429f9a717917a361aa8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd3a22a2ab1346f6a9ef030c11c54310":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6074c08ebf04fee81dbbba753c78c66":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4535ac5a73e4a8188a1d87afbd82683":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3789d24d92b46c988be74652796d3da":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"768fcf4b6e894478867740d8c1a8684e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d5dc12aee8f414cba77e1dfe9847a56":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d18da17cf13a49e0aedde0616822945a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fca7065db05d4728a085065fd8399465","IPY_MODEL_6751b561b46340c293de149e00de7de1","IPY_MODEL_78d294b5f94c4c368dd769a9914cc136"],"layout":"IPY_MODEL_e5d7145412664d1ba792c4de44e2bdd5"}},"fca7065db05d4728a085065fd8399465":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90ac18dd34a545eda2feb5f46fa6702b","placeholder":"​","style":"IPY_MODEL_2149b19e9cd5431ab86be86a43271824","value":"Loading checkpoint shards: 100%"}},"6751b561b46340c293de149e00de7de1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffb071d8ee4c4e23b8b1d1946743698e","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_53e007fd13444d46ab72a7240a5ba3f7","value":2}},"78d294b5f94c4c368dd769a9914cc136":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b750ce6b3e344a8ca85ad45ba03dd6be","placeholder":"​","style":"IPY_MODEL_65d527e5209d40f7a7ade68b12edf560","value":" 2/2 [00:28&lt;00:00, 12.48s/it]"}},"e5d7145412664d1ba792c4de44e2bdd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90ac18dd34a545eda2feb5f46fa6702b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2149b19e9cd5431ab86be86a43271824":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ffb071d8ee4c4e23b8b1d1946743698e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53e007fd13444d46ab72a7240a5ba3f7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b750ce6b3e344a8ca85ad45ba03dd6be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65d527e5209d40f7a7ade68b12edf560":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35751bde456741f09b7385df8ce0305e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7ebadcdc67c7411b86e547cdd5f1b9a5","IPY_MODEL_d8ba2095bf8a4d0598e2a7b31b2ee287","IPY_MODEL_ecc2be37cd4247a29b4227283e847c2d"],"layout":"IPY_MODEL_195d01d71f4f4d17bed0ccb34b6eccc7"}},"7ebadcdc67c7411b86e547cdd5f1b9a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e19c3799bc3f4b27bd363ae0dc4e6a0a","placeholder":"​","style":"IPY_MODEL_51c05445c20d4844b7bf11ab5c394ee3","value":"Generating train split: "}},"d8ba2095bf8a4d0598e2a7b31b2ee287":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ed95a065038450d87f76a75439517d3","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7b50ea435396435c92a18f42ebc853c5","value":1}},"ecc2be37cd4247a29b4227283e847c2d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_211a294584fd49f28c33ebc149c3aefa","placeholder":"​","style":"IPY_MODEL_b91a03ec4afa4b1b99e5e8d0fa341f73","value":" 73431/0 [00:10&lt;00:00, 7335.42 examples/s]"}},"195d01d71f4f4d17bed0ccb34b6eccc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e19c3799bc3f4b27bd363ae0dc4e6a0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51c05445c20d4844b7bf11ab5c394ee3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ed95a065038450d87f76a75439517d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"7b50ea435396435c92a18f42ebc853c5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"211a294584fd49f28c33ebc149c3aefa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b91a03ec4afa4b1b99e5e8d0fa341f73":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8df09c3a2bb84fbc9020934af5b1f461":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ecc7fce680ca45c4a7eb891f854d9082","IPY_MODEL_baee74db08d645a1a27d3da8eeec8139","IPY_MODEL_1af96b4146854275ae7c4b6df1896a05"],"layout":"IPY_MODEL_ea8a05603c03403d85acfc606af2f2f1"}},"ecc7fce680ca45c4a7eb891f854d9082":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a93af2821914b44986459bb2e22e39c","placeholder":"​","style":"IPY_MODEL_ab6e38e9dcae4ac7857275893af8dc7d","value":"Map:  12%"}},"baee74db08d645a1a27d3da8eeec8139":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c7d5b6d0e8d4b1485a74516e1a2ba4a","max":73431,"min":0,"orientation":"horizontal","style":"IPY_MODEL_63f69cae6b92427eabf938cf356408b9","value":9000}},"1af96b4146854275ae7c4b6df1896a05":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3438eb93df6e454883cf616a2c0abf66","placeholder":"​","style":"IPY_MODEL_b794c27b273a460193bed36e5881515d","value":" 9000/73431 [00:39&lt;03:53, 276.27 examples/s]"}},"ea8a05603c03403d85acfc606af2f2f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a93af2821914b44986459bb2e22e39c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab6e38e9dcae4ac7857275893af8dc7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c7d5b6d0e8d4b1485a74516e1a2ba4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63f69cae6b92427eabf938cf356408b9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3438eb93df6e454883cf616a2c0abf66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b794c27b273a460193bed36e5881515d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}