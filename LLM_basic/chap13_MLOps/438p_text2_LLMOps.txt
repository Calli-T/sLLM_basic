439p
{   LLMOps
    {   LLMOps는 MLOps랑 뭐가 다른가
        일단 대부분의 머신러닝 모델보다 크다.
        그리고 상업용 모델을 IT 공룡들이 API 형태로 제공함, 오픈소스도 많음 ※ 그리고 학습을 처음부터 시작하는 경우가 적음
        일단 하는건 생성 작업이라 정량 평가가 어려움 ※ 분류나 회귀에 못쓰는 건 아님
    }

    {   모델을 어디서 가져올 것인가?
        머신러닝은 분류나 회귀등 하나의 문제를 해결하는 모델이나,
        LLM은 모델의 파라미터의 수가 많고 여러 문제를 해결하기 위해 만들어지는 경우가 많다. ※ 다운태스크건, 여러 문제를 물어보건, 사전학습된걸 다른데 쓰건간에...
        그래서 많은 패턴을 담을 수 있어야하고, 모델이 커지는 추세이며, 리소스도 많이 먹기 시작했다.

        그리고 큰 모델이라 비용이 많이 드는데다가,
        해결하고자 하는 문제와 난이도도 서로 다름에 따라
        상업용 모델과 오픈소스 모델로 나뉘게 되었다.

        상업용은 보통 쉬운 난이도에 고성능이나 / 버전 변경에 따라 프롬프트가 취약하며 / ※ 미세 조정은 회사 정책 별로 다름
        오픈 소스는 미세 조정이 자유롭고 / 대신 직접 인프라를 관리해야한다

        오픈 소스 모델을 쓰려면
        1~7장의 양자화같은 추론 경량화, lora나 플레시어텐션 같은 학습 효율 상승의 모든 기술을 다 꼴아박아야함
    }

    {   문제는 어떻게 해결할 것인가?
        LLM을 사용례에 맞게 최적화하려면
        사전 학습 / 미세 조정 / 프롬프트 엔지니어링 / RAG
        오픈 소스 모델은 모든 것이 자유롭지만 ※ 사전 학습은 그래도 리소스가 너무 많이 들어서 빡세다
        상업 모델은 미세 조정이 불가능하거나 제한되고 프롬프트 엔지니어링와 RAG가 가능하다

        ※ 사전 학습의 경우
        보통 머신러닝은 처음 부터 직접 모델을 학습했으나, LLM은 힘들다 ※ 파라미터를 세는 단위가 10억이다
        70B 모델은 사전 학습에 20만 달러가 들어간다

        ※ 미세 조정의 경우
        지도 미세 조정이나 DPO같은 경우는 사전 학습보단 비용이 덜하지만, 여전히 모든 파라미터를 쓰므로 많은 GPU가 필요하다
        LoRA나 QLoRA를 쓰면 성능과 비용 trade-off 어느정도 가능

        ※ 프롬프트 엔지니어링의 경우
        학습이 완료된 LLM의 경우, 프롬프트의 변경으로 성능 향상을 어느정도 끌어올릴 수 있다
        템플릿 / 메개변수 / 컨텍스트 관리 / 단계적 프롬프트 설계 등등
        MLOps에서 하이퍼파라미터나 데이터셋에 따라 실험과 버전 관리를 했는데,
        이 경우,프롬프트도 실험 대상이 된다.
        W&B나 MLflow등에서 사용가능

        ※ RAG의 경우
        검색할 문서와 임베딩 모델과 벡터 DB를 만들어 파이프라인을 만들면,
        프롬프트에 RAG 결과물을 반영하여 보강할 수 있다.
        위에 셋을 추가적으로 관리하고 운영해야함
    }

    {   평가는 어떻게 할건가
        {   LLM은 평가가 왜 어렵나?
            생성물에 대한 정량 평가가 어렵다. ML은 정확도, 재현율, F1 점수 등 정량 지표가 있음
            작업도 다양하고 답도 다양한 갈래가 있어서 특정 지표로 모두 평가할 수는 없음
            애시당초에 완전히 풀리지 않은 문제임
        }

        {   지금 쓰는 지표의 종류는?
            {   정량적 지표의 경우
                BLEU: 기계 번역 결과와 사람이 번역한 결과의 유사도를 측정
                ※ n-gram 기반으로 (사람이 번역한) 참조 문장과 모델이 생성한 문장 간의 정밀도 측정
                ※※ 문장의 유창성이나 문법적 오류는 반영 불가
                ※※※ 사람의 번역이 필요하고, 여러 개의 번역문이 있으면 더 나음

                ROUGE(Recall-Oriented Understudy for Gisting Evaluation): 모델의 요약문과 사람이 작성한 요약문을 사이의 n-gram 중복도를 재현율 관점에서 측정함
                ※ gisting: 특정 문서나 대화의 요점을 요약하는 과정
                ※※ 단어의 순서나 문장 구조는 고려하지 않음
                ※※※ n-gram recall은 모델이 생성한 n-gram의 일부가 실제 문장에서 얼마나 잘 일치하는지를 측정
                ※※※※ n-gram은 n개 연속된 단어의 묶음

                perflexity: 모델이 새로운 단어를 생성할 때의 불확실성을 수치화한 것
                ※1 크로스 엔트로피의 지수화된 버전, 2^H(p)라고 한다
                ※2 H(p)는 엔트로피를 의미하며, 수식은 H(p) = -Σ(i=1, n, p(x_i) * log(p(x_i)))
                ※3 정보이론에서 사건하나의 정보량은 −log(p(x_i))이나, 확률을 곱해야하므로 p(x_i)를 곱하는 것
                ※4 위 수식에서 전체 불확실도의 합을 계산할 수 있게되는 것이다.
                ※5 정보량은 확률이 높으면 적고 낮으면 높다. 혼란도는 해당 사건이 발생했을 때 제공하는 정보량으로 정의한다.
                ※6 값이 2^H(p)로 나왔다면, (평균적으로) 선택지 중에 하나를 선택해야하는 상황이라고 해석할 수 있다.
            }
        }
    }
}