로라 지도 미세 조정을 해보자

{   사전 지식
    기법에 관하여
    1. 모델의 사전 지식이 충분하면 lora로도 충분하나, 아니면 전체 파라미터의 미세조정이 필요하다

    성능과 모델에 관하여
    1. llama 계열 한국어 모델 성능이 뛰어난건 bllossom
    2. 한국어 sLLM 벤치마크는 LogicKor에서, 그러나 2024-07까지의 기록만 있다
    https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard#/?search=korean 이건 허깅페이스 벤치
    https://huggingface.co/MLP-KTLim/llama-3-Korean-Bllossom-8B 블로썸

    LoRA에 관하여
    1. QLoRA는 원본 모델은 양자화 한채로 추론하는 LoRA임
    2. 로라는 주로 Q,V 프로젝션 레이어에 추가됨
    3. 로라를 통과한 값은 Q, V 선형 레이어를 통과한 값에 더해짐
    4. 로라는 원본 Q, V proj와 크기가 같지 않으나,
    저차원 투영/ 고차원 복원 두 단계를 거치므로
    이를 통과한 행렬은 원본 QK를 통과한 행렬의 크기와 같음

    Autotrain과 LoRA에 관하여
    1. Autotrain에서, --use-peft옵션을 사용하면 LoRA를 포함한 PEFT 기술을 활성화한다.
    lora-r, lora-alpha, lora-dropout옵션이 lora 관련 옵션
    2. (허깅페이스에서) 이를 원본 모델과 합치려면 peft 모델이 필요함

    관련 라이브러리에 관하여
    1. Autotrain을 사용하지 않으려면 Trainer 라이브러리도 있고, 아니면 그냥해도된다
    2. 이 때 옵션은 TrainingArguments 라이브러리쓰며, 명시적으로도 가능하나 json으로도 작성이 가능하다.

    입력에 관하여
    1. 학습 데이터는 instruction 지시/input 입력된 자료/output 정답으로 나뉜다
}

{   할일
    1. 뭘 만들건지 정하자
    2. 어디서 데이터를 가져올 건지 찾아보자
    3. 모델과 입력 형식을 알아보자
}

고객 응대 QNA 자료를 싹 모아서 미세 조정을 하자
블라썸 8B를 쓰자
그런다음 원하는 자료로 LoRA

----- 0314 -----
블라썸 양자화 하니까 의외로 헛소리만 하는데?


----- 0315 -----
알아낸거
1. 블라썸 이거 사용방법이 따로 있더라, prompt와 instruction이 서로 달라
둘 다 써줘야함
2. 양자화 안하면 '램딸려서' 정지함
3. 블라썸은 프롬프트를 system 지시사항과 user의 질문으로 나눠둠,
시스템의 지시사항은 어떤식으로 대답, 예를들어 모르면 잘모른다고 해라 등등을,
user의 질문은 일반적인 프롬프트임
시스템의 지시사항을 고정해두고 user 질문을 바꾸는 방식인듯함
그리고 이런 프롬프트는 모델의 입력에서 임의로 나눠둔 방식이며, 나누는 방식은
프롬프트에 태그삽입/대화용 템플릿을 갖춘 프롬프트/특수 토큰 (예: <|SYSTEM|>, <|USER|>, <|ASSISTANT|>)의 방식이 있음