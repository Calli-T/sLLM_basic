{   Agent
    {   서론
        AI에서 에이전트란, 사용자를 대신하여 목표를 추구하고 태스크를 완료하는 소프트웨어 시스템
        ※ 구글의 설명, AWS의 경우는 사람의 개입 없이 특정 작업을 수행하는 자율 지능형 시스템이라고 하는데, 거기서 거긴것같음
        ※ 책에서는 주변 환경을 감각을 통해 인식하고 의사결정을 내려 행동하는 인공적 개체라고 사용함

        한 에이전트가 한 목표에 -> 단일 에이전트
        여러 에이전트가 한 목표를 위해 협력 -> 멀티 에이전트

        에이전트는 LLM과 RAG를 구성요소로 둔 만큼, 성능 평가도 정답은 없다고 한다.
        평가 방식을 살펴보고, AgentBench라는 벤치마크 데이터셋을 알아본다고 하고

        실습은 AutoGen이라는 MS의 멀티 에이전트 프레임 워크를 사용한다고 한다.
        여기에 멀티 모달을 곁들인
    }

    ※ 라이브러리는 pyautogen[retrievechat]==0.2.6과 같이 설치하더라, 찾아보니 의존성 관련문제인듯

    {   에이전트의 구성요소
        ※ 개념적 요소인듯하다
        '감각'을 통해 외부 환경과 사용자의 요청을 인식하고,
        '두뇌'를 통해 가지고 있는 지식이나 기억을 짚어보고, 계획을 세우고 추론하여, 다음 행동에 관한 의사결정을 한다
        적절한 도구를 선택해 '행동'한다

        '감각'-'두뇌'-'행동' 싸이클은 간단한 작업에는 한 단계로 끝날 수도 있으나,
        복잡한 작업은 여려 반복을 거쳐야하며,
        주어진 일을 세분화하고 단계별로 필요한 작업을 수행하여 요청을 완수하도록 한다.
        ※ 사람의 작업 방식과 개념적으로 유사하다고 한다

        {   에이전트의 두뇌란
            에이전트의 두뇌 역할을 할 것이라 기대되는 기술은
            심볼릭 AI, 강화학습, 메터러닝 ※ 전이학습의 일종
            등등이 있고,
            요새는 LLM으로 몰리는 추세인듯

            기억은 지금까지 수행한 사용자와의 대화나, 행동?을 저장한 것을 확인하고,
            상황을 이해하는데 필요한 지식이 있다면 검색해서 활용한다. (??? 이거 프롬프트랑 결과물에 RAG를 적용한거 아닌가?)
            기억과 지식으로 보강한 정보를 바탕으로 목표 달성을 위한 작업을 세분화하는
            계획 세우기 단계를 거쳐, (※ RAG인것같다)
            다음에 어떤 행동인지 필요한지 결정하고 행동한다.

            LLM은 기억 보강 계획 행동 모두 가능한데,
            요청을 이해하는 능력이 뛰어나고, RAG로 필요한 지식을 검색하여 활용할 수 있으며,
            추론이 가능하고, 문맥학습과 같이 새로운 작업에 대응하는 일반화 능력도 갖고 있다.

            현재까지의 판단 내용을 기록하거나,
            이후에 필요할 수 있는 유용한 지식을 저장하려면,
            효율적으로 요약하는 기능도 필요한데, LLM은 요약도 훌륭하게 수행한다.
            ※ RAG를 무한정으로 쓰진 못하니까, 필요하긴 하겠지. 프롬프트 길이는 무한이 아니다.

            행동에 필요한 도구를 쓰려면, 설명이 필요하고, 그걸 이해하는 능력도 필요한데, LLM은 둘 다 있다.

            요약?: 에이전트에서, 계획(+ 추론)과 행동(+ 도구사용)은 LLM이, 기억과 정보 찾기와 보강은 RAG의 도움을 받아서 수행
            (자세한건 나중에)
        }
        {   에이전트의 감각
            LLM은 기본적으로, 텍스트를 입력으로 받고, 텍스트를 출력한다.
            여러 종류의 데이터를 입력하는 방법은 2가지가 있다.
            1. 데이터를 뭐든 간에 텍스트로 변환해서 사용 ※ Whisper로와 같은 모델로 텍스트로 변환 (음성)
            2. 같은 벡터 공간을 공유하는 임베딩으로 데이터를 사상(mapping)하여 사용
                ※ 비디오 인코더와 오디오 인코더를 (영상/음성) 사용해서 임베딩으로 변환, LLaVA의 처리 방법
                ※ 이 경우, 14장의 설명처럼 LLM 자체를 건들기 보단 인코더를 추가하는편
        }
        {   에이전트의 행동
            LLM은 텍스트만을 생성 가능한 백본이므로,
            외부에 영향을 끼치려면 LLM만이 사용할 수 있는 도구를 제공해야 한다.

            도구 예시는
            검색 api
            코드 실행기
            음성, 이미지 생성기 ※ Diffusion 계열
            물리적인 행동 ※ 뭐 집게발 같은거를 연결한다던지
            번역기, 요약기 등등 ※ 이건 LLM 모델인가
        }
    }

    {   에이전트 시스템의 형태
        {   단일 에이전트의 경우
            AutoGPT는 한 에이전트로 하나를 모두 처리한다.
            작업 계획, 작업 수행 선택 이 과정을 반복해서 문제를 해결한다

            해당 과정은 다음과 같이 진행된다
            일단 프롬프트를 통해 모든 결정을 내린다. ※ 예시를 보면 프롬프트에 뭘 하라고 다 쓰여져 있다.

            {   단일 에이전트(AutoGPT)의 프롬프트 예시문 (491p) 문석
                뭐가 있냐면 ※ 모두 평문이다. LLM의 언어 해석 능력
                1. 에이전트에 이름과 역할 부여 ※ 당신은 ~~ 입니다. 뭘 하세요 라고 하면 잘 수행하는듯
                2. 목표 ※ 예시문은 꽃에 관한 짧은 이야기를 써라
                3. 제약사항 ※ 예시문은 4000단어 제한, 긴건 파일에 저장, 사용자에게 물어보지 않기
                4. 명렁어: 구글 검색, 웹사이트 검색... 도구로 할일을 쭉쭉 적어서 준다. 마지막 할일은 task complete가 명시되어있음
                    ※ 예시문에서, 검색에 필요한 검색어 인자를 'google'이라는 도구 이름 인자를 LLM이 알아서 뽑아서 알아서 처리한다
                5. 성능 평가: 에이전트가 지속적으로 목표를 달성하는데 초점을 두고, 자원을 효율적으로 쓰라고 명령하고 있다.
                6. 응답 형식: 응답 형식을 주어, 해당 방식으로 응답하도록 한다.
            }

            단일 에이전트는 매우 편리하나.
            내부 LLM의 성능이 낮은 경우 빈번하게 실패하고 잘 동작하지 않으므로,
            목표가 명확하고 작업의 크기가 작은 특정 경우에 한정하여 활용하는 것이 좋다고 한다.

            단일 에이전트는 사람의 피드백이나, 에이전트들 간에 협력으로 보환할 수 있다.
        }

        {   에이전트에 사람 협력자를 붙여준 경우 (492p)
            {   이거 안 중요하기 보다는, 엄밀한 내용 뭐 context 이런게 없어서 힘듬, Agent는 책을 따로 사서 보든가 해야지
                ChatGPT에 문제를 요청하고 (코드짜기) 피드백을 주면서 (버그남) 수정을 해가는 모습을 예시로 들고 있다.
                또, 특정 도메인에서 전문성이 떨어지는 경우는 사용자가 문제 해결 과정에서 직접 개입하는 것이 특히 중요하다고 한다.
                사용자가 명확한 명령과 피드백으로 에이전트의 작업 방향을 설정하고, ※ 지시자 - 실행자 패러다임
                에이전트는 자동으로 수행해서 사용자가 빠르고 편한 작업을 진행한다고 한다.
                ※ 상담봇 같은 경우는 동등한 파트너 패러다임
            }
        }

        {   멀티 에이전트
            LLM에 구체적인 프로필을 부여하면, 관련된 작업의 전문성을 높여 결과 품질을 높일 수 있다고 한다. ※ 대화의 문맥을 쥐어주는 역할이고, 해당 분야의 지식을 더 사용하도록 한다고 한다 (GPT 피셜)
            에이전트 각각에 서로 다른 프로필을 부여하면, 전문성이 높아진 각 에이전트들의 협력으로 작업의 품질이 향상될 수 있다고 한다.

            여러 작업에 여러 맞춤 에이전트를 만들어 주면, 문제 해결 확률을 높일 수 있다고 한다.
            에이전트끼리는 대화를 통해 작업 진행과 결과를 공유하는데,
            모두 함께 대화를 진행하는 수평적 대화와 매니저가 주도하는 위계형 대화가 있다고 한다.

            프레임 워크는 MS의 AutoGen, MetaGPT, CrewAI 등이 있다고 한다.
        }
    }

    {   에이전트 평가하기
        {   어떻게 평가할건데?
            튜링테스트: 설명따윈 필요없는 유명한 테스트이나 한 가지 짚고 가자면
            LLM으로 평가할 수도 있다고 한다.

            벤치마크 데이터셋으로도 가능하다
            AgentBench데이터셋은 8개의 작업으로 평가하고, 일반화 성능이 괜찮다고 한다
            집안일, 상황 퍼즐, 웹쇼핑 등등...
        }

        {   벤치마크 지표는 뭘 쓸건데?
            이 중에서는 유용성이 가장 활발히 연구되는 지표라고 한다.

            유용성: 작업 성공률 등
            사회성: 에이전트끼리의 상호작용에, 숙련된 언어 사용, 협력이나 협상 요청 사용, 부여된 역할을 잘 이해하는지 등등
            가치관: 거짓말 여부, 편견이 있나, 사회에 해가 되는가 등등

            ※ 얘는 LLMOps에 가까운것 같은데?
            진화 능력: 위 셋에 더하여, 변화하는 상황에 맞춰 스스로 발전 할 수 있는가? 등을 따짐
            지속적인 학습, 목표 설정 및 달성, 환경 적응
        }

        칭화대 벤치셋인 AgentBench에서, 오픈소스 LLM이 상용 LLM보단 많이 딸린다고 한다.
        그 이유를 분석해보니
        LLM 에이전트는 출력이 원하는 형식으로 안나왔을 때 실패할 확률이 크다고 한다.
        반면, 고득점 모델은 코드 데이터 자체나 고품질의 정렬 데이터셋으로 SFT 했다고 한다.
    }
}