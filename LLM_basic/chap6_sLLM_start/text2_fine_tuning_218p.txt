218p
{   딱히 안중요한 내용
   2023년 12월 기준 7B이하 한국어 사전 학습 모델 중 가장 높은 성능을 보이는건 beom/Yi-Ko-6B라고함
   (지금은 딥시크가 다 때려눕혔지 않았을까?)
   중국의 01.AI가 발표한 영어-중국어 모델의 한국어 확장판임
}
※ 모델의 임시 저장 장소는 from_pretrianed함수의 인자, 'cache_dir'를 사용하면 된다
※ 7B 모델을 FP16으로 저장해놨을 때 14 GiB정도 사용함

잠정 폐기 사유: 일단 무료 사용량이 없어 GPT-4o를 결제하지 않고서는 불가능함
{   sLLM 추론과 성능 평가
    218p부터 예시 코드의 내용은
    - make_inference_pipeline: 모델과 토크나이저로 이뤄진 파이프라인 반환하는 함수
        --from_pretrained
            ---device_map인자를 auto로 하면 시스템 리소스에 분배되는게 자동인듯함
            ---load_in_4bit인자는 True일 때 4비트 양자화 함
            ---bnb_4bit_compute_dtype은 연산 직전에 양자화된 가중치를 바꿀 dtype을 정하는 것이며, 연산 후에는 다시 4비트 양자화로 변환됨

        --인자로는 모델 이름을 받는다

    이하 example에는 DDL과 Question과 빈 SQL이 구분되어있고,
    파이프라인에 넣는 코드가 있다

    pipeline의 인자는 해당코드를 참조
}
{   데이터셋을 불러와서 기초 모델의 성능을 평가하는 코드 220p
    데이터셋 불러오기
    -> 프롬프트로 만들기(pandas로 줄당해서 make_prompt함수에 넣고 전처리)
    -> 모델 파이프라인에 넣고 sql 생성
    -> 평가를 위한 jsonl 생성
    -> 이후 미리 짜둔 코드로 GPT-4 평가 수행
    평가 부분은 GPT가 유료화를 진행해서, 생략하거나 대체해야할듯?
}

221p의 코드는 학습데이터를 불러오는것과

중요: 허깅페이스에서, autotrain llm은 명령어로 코드 없이 llm을 학습시키는 것이다!!!

{
    이번장에서 해볼거
    sLLM 허깅페이스로 추론
    미세조정
    로라

    안할거
    GPT-4o로 성능평가 - GPT 무료 크레딧 사라짐

    나중에 할거
    LLM으로 LLM 평가하는 다른 방법 찾기
    GPT 결제해보기
}