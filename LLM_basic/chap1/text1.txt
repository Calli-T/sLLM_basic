책 내용 중요한거 간단 요약
35p
딥러닝은 비정형 데이터의 패턴 인식에 뛰어난 성능을 보여 주류가 됨
LLM은 딥러닝을 사용한 자연어 처리 중 자연어 생성 분야 속함

36p
딥러닝 문제해결법: 문제 유형별 모델 준비 -> 문제에 대한 학습 데이터 준비 -> 반복적으로 모델에 입력
딥러닝에선 머신러닝과 다른게 데이터의 특징을 알아서 뽑는다
특징을 찾고 추출&분류하는 과정을 학습함

37p
컴퓨터는 숫자만 처리가능 단어는 처리 못하기 때문에
데이터를 (데이터의 의미와 특징을 담은) 집함으로 표현, 이를 '임베딩'이라고 함

책의 예시는 MBTI로, 0.5를 기준으로 +-를 각 알파벳으로 표현함
0.3은 I, 0.7은 E인 식으로

38p
임베딩 표현은 거리를 계산할 수 있으며 (아마 벡터 간 차이의 노름?)
이를 이용해 검색&추천, 클러스터링, 이상치 탐지 등에 사용

39p
단어는 숫자로 표현할 때 word2vec과 같은 임베딩 모델을 사용해
수 만~수십만 개의 숫자로 표현한다

딥러닝은 특징을 추출하는 방법을 알아서 학습하므로
다른 말로 하면 사람이 각 숫자의 의미를 정하는 것이 아니므로
값들 각각의 의미는 알기 어렵다

41p
'언어 모델링'은 텍스트의 다음 단어를 예측해 텍스트를 생성하는 방식

언어의 특성을 학습하는 사전 학습 과제로도 언어 모델링을 많이함
전이학습: 한 문제를 해결하는 과정에서 얻은 정보를 다른 문제에 풀 때 사용하는 방식

전이 학습은 사전 학습과 미세 조정 두 단계로 나눠 학습을 진행
언어 모델링은 자연어 처리 분야에서 사전 학습을 위한 과제로 사용

이미지 인식 분야에서는 자연어 처리 분야보다 먼저 이미 전이학습 사용했음
-> Imagenet 모델 학습한거로 졸업 과제로도 썼지 아마

다운스트림 (과제): 사전 학습 모델을 미세 조정해 풀고자 하는 과제

사전학습으로 대량의 데이터를 학습했다면,
현재 해결하려는 문제의 데이터로 추가 학습을 하여 '미세 조정' 할 수 있다
소량의 데이터를 학습하는 과정 자체가 파인 튜닝 기법의 일부
미세 조정은 재학습이며
일부 레이어만 학습하거나, 일부 레이어는 고정하고 나머지 레이어는 고정할 수 있다

이미지넷 데이터로 학습한 모델의 가중치를 고정하고
분류 헤드 부분만 (레이어를) 분류하고자 하는 데이터셋(자동차, 유방암 등)으로 새로 학습하는 방식은
사전 학습에 비해 적은 양의 학습 데이터만 사용하므로, '미세' 조정이라 부른다
-> 당장 effinet, ViT등을 imagenet으로 학습시킨걸 FC layer에 넣어 분류하는 과정을 거친 졸업작품이 생각난다

42p
'언어 모델링' 즉 다음 단어를 예측하는 방식으로 만든 사전학습이 자연어 처리 분야의 성능 GOAT라함
훨씬 적은 레이블 데이터로도 기존 지도 학습 모델의 성능을 뛰어넘는다고 한다

44p
그림에
언어 모델 사전학습
언어모델 미세 조정
분류 모델 미세 조정의 흐름을 잘 보여준다

45p
길이가 다양한 데이터의 형태를 시퀀스라고 한다
텍스트 오디오 시계열 등등....
{ 중요한건 트랜스포머 모델이 이전 모든 단어들 사이의 관계인 맥락을 '한꺼번에' 계산
    RNN이나 Transformer 아키텍쳐로 대표되는 다양한 모델이 사용됨
    RNN은 텍스트를 순차적으로 처리해서 지금까지 들어온 입력을 하나의 잠재 상태으로 텍스트의 '압축된' 맥락을 만들어 내는데,
    이 때 입력이 길어지면 앞선 단어의 의미가 희석된다
    Transformer는 '어텐션' 연산을 통해 이전 모든 단어의 관계를 한번에 계산하여 다음 단어를 예측한다.
} -> 한꺼번에 사용하는 그 '맥락'이라는게 각 단어의 임베딩 벡터?를 의미하는듯 / 엄밀한 의미는 아닌것 같음

47p
모든 단어의 맥락을 그대로 사용하므로 메모리 사용량이 많고 시간도 오래걸림 -> 대신 트랜스포머는 성능이 좋다
RNN은 그 반대
성능이 같거나 비슷하며 좀 덜쓰는 아키텍쳐가 아직 연구중이며, '맘바'가 대표적

49p
언어 모델은 원본 언어를 중요한 특징을 남기는 손실 압축을 진행한다
모델이 클 수록 많은 특징을 학습할 수 있으므로, 패러미터 수가 성능과 관련이 있다.
물론 무한정 가능한건 아니고
원본 데이터 크기가 학습가능한 패턴의 상한선이라 여겨진다.

50p
사전학습된 GPT3을 chat gpt로 바꾸는 과정은
지도 미세 조정과 RLHF라는 과정이었다.(Reinforcement Learning from Human Feedback)
이를 통해 할말 다음말을 생성하는 기술에서,
사용자의 요청을 해결할 수 있는 텍스트를 생성하도록 학습됨

정렬: LLM이 사용자에 요청 의도에 맞게 답변하도록 하는것
지도 미세 조정: 정렬을 위한 학습 과정, 사전 학습된 언어모델을 '지시 데이터셋'으로 추가 학습 하는것
지시 데이터셋: 사용자 요청&지시 사항과 그에 맞는 답변

사용자가 더 좋아하는 답변을 데이터셋으로 구축한걸 '선호 데이터셋'이라하며
이를 기반으로 '리워드 모델'을 만들어 LLM이 점점 더 높은 점수를 받도록 하는 과정은 강화학습의 일부이다.
그리고 사람의 피드백을 상요하므로 RLHF라함

51p
기존 자연어 처리 연구는 이해와 생성 두 도메인으로 나뉨
각각의 작업은 각각의 모델로 사용했으나 LLM으로 통합
언어 이해와 생성이 뛰어난 LLM,
LLM의 다재다능함은 언어 인해와 생성이 동시에 필요한 여러 복잡작업에 적용가능

54p
원하는 도메인으로 작은 모델에 추가 학습을 하는 과정이 가능한 sLLM
기업이 자신의 조직에 특화된 sLLM을 개발하기 위한 시도를 함

트랜스포머 아키텍쳐와 어텐션 연산은 병렬처리에 많은 비용과 GPU, 탄소 배출 등등을 사용하며 이를 개선하기위해
양자화: 파라미터를 더 적은 비트로 표현
LoRA(Low Rank Adaptation): 모델의 일부만 학습
등등의 방식과,
어텐션 연산의 개선해 효율적인 학습(6장)과 추론(8, 9장)을 가능케하는 연구가 있다고한다.

환각현상: 잘못된 정보나 실존하지 않는 정보를 만들어내는 현상
정보의 소실, 입력 데이터의 사실 유무 판단 불가, 그럴듯하게만(=확률론적인 생성)하는 LLM의 특성에서 기인함

55p
RAG 기술은 LLM이 답변할 때마다 정보를 추가하여 잘못된 정보를 생성하는 환각 문제르 ㄹ줄인다

56p
LLM의 확장 방향성
1. 멀티모달
2. 계획 -> 의사결정 -> 행동 수행을 전부하는 에이전트,
에이전트의 두뇌로 쓸 수 있는 것은 언어 이해와 추론 능력이 뛰어나기 때문
3. (긴 입력을 처리할) 새로운 아키텍쳐
